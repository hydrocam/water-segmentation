{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvvBP7S-dZPM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR0hPcOKbGSZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "# === 1. Load stage data ===\n",
        "def load_stage_file(file_path):\n",
        "    return pd.read_csv(file_path, comment=\"#\")\n",
        "\n",
        "gt_2023 = load_stage_file(\"/content/drive/MyDrive/CIROH_UWRL/BlacksmithFork/data_analysis/BSF_CONF_BA_SourceID_1_QC_0_Year_2023.csv\")\n",
        "gt_2024 = load_stage_file(\"/content/drive/MyDrive/CIROH_UWRL/BlacksmithFork/data_analysis/BSF_CONF_BA_SourceID_1_QC_0_Year_2024.csv\")\n",
        "gt_2025 = load_stage_file(\"/content/drive/MyDrive/CIROH_UWRL/BlacksmithFork/data_analysis/BSF_CONF_BA_SourceID_1_QC_0_Year_2025.csv\")\n",
        "\n",
        "# Combine and filter\n",
        "gt_all = pd.concat([gt_2023, gt_2024, gt_2025], ignore_index=True)\n",
        "gt_all[\"timestamp\"] = pd.to_datetime(gt_all[\"DateTimeUTC\"])\n",
        "gt_all = gt_all[[\"timestamp\", \"Stage\", \"Discharge_cms\"]]\n",
        "gt_all = gt_all[gt_all[\"Stage\"] != -9999.0]\n",
        "gt_all = gt_all.rename(columns={\"Discharge_cms\": \"Discharge\"})\n",
        "\n",
        "# === 2. Load ROI data ===\n",
        "roi_df = pd.read_csv(\"/content/drive/MyDrive/CIROH_UWRL/BlacksmithFork/data_analysis/blacksmithcsv.csv\")\n",
        "roi_df[\"timestamp\"] = pd.to_datetime(roi_df[\"image_timestamp\"]).dt.round(\"15min\")\n",
        "\n",
        "# Extract ROI1 and ROI2\n",
        "roi_vals = roi_df[\"roi\"].str.extract(r\"\\{(\\d+),(\\d+)\\}\")\n",
        "roi_df[\"roi1_pixels\"] = pd.to_numeric(roi_vals[0], errors=\"coerce\")\n",
        "roi_df[\"roi2_pixels\"] = pd.to_numeric(roi_vals[1], errors=\"coerce\")\n",
        "roi_df_clean = roi_df[[\"timestamp\", \"roi1_pixels\", \"roi2_pixels\", \"iou_score\"]]\n",
        "\n",
        "# === 3. Merge stage and ROI data ===\n",
        "merged_df = pd.merge(gt_all, roi_df_clean, on=\"timestamp\", how=\"left\")\n",
        "\n",
        "# === 4. Linear regression filling ===\n",
        "train_df = merged_df.dropna(subset=[\"Stage\", \"roi1_pixels\", \"roi2_pixels\"])\n",
        "model_roi1 = LinearRegression().fit(train_df[[\"Stage\"]], train_df[\"roi1_pixels\"])\n",
        "model_roi2 = LinearRegression().fit(train_df[[\"Stage\"]], train_df[\"roi2_pixels\"])\n",
        "\n",
        "merged_df[\"roi1_filled\"] = merged_df[\"roi1_pixels\"]\n",
        "merged_df[\"roi2_filled\"] = merged_df[\"roi2_pixels\"]\n",
        "\n",
        "missing_roi1 = merged_df[\"roi1_pixels\"].isna()\n",
        "missing_roi2 = merged_df[\"roi2_pixels\"].isna()\n",
        "\n",
        "merged_df.loc[missing_roi1, \"roi1_filled\"] = model_roi1.predict(merged_df.loc[missing_roi1, [\"Stage\"]])\n",
        "merged_df.loc[missing_roi2, \"roi2_filled\"] = model_roi2.predict(merged_df.loc[missing_roi2, [\"Stage\"]])\n",
        "\n",
        "# === 5. Smooth filled ROI signals ===\n",
        "def get_valid_window_length(series, desired=31):\n",
        "    n = len(series)\n",
        "    return desired if (n >= desired and desired % 2 == 1) else (n if n % 2 == 1 else n - 1)\n",
        "\n",
        "window_roi1 = get_valid_window_length(merged_df[\"roi1_filled\"].dropna(), 31)\n",
        "window_roi2 = get_valid_window_length(merged_df[\"roi2_filled\"].dropna(), 31)\n",
        "\n",
        "merged_df[\"roi1_smoothed\"] = savgol_filter(\n",
        "    merged_df[\"roi1_filled\"].fillna(method='ffill'), window_length=window_roi1, polyorder=2)\n",
        "merged_df[\"roi2_smoothed\"] = savgol_filter(\n",
        "    merged_df[\"roi2_filled\"].fillna(method='ffill'), window_length=window_roi2, polyorder=2)\n",
        "\n",
        "#merged_df[\"Stage_ft\"] = merged_df[\"Stage\"] / 30.48  # 1 ft = 30.48 cm\n",
        "\n",
        "start_date = \"2023-12-04\"\n",
        "end_date = \"2025-04-14\"\n",
        "\n",
        "filtered_df = merged_df[(merged_df[\"timestamp\"] >= start_date) & (merged_df[\"timestamp\"] <= end_date)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.head()"
      ],
      "metadata": {
        "id": "6QbU1uUVGdld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6. Plot final results ===\n",
        "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "ax1.plot(filtered_df[\"timestamp\"], filtered_df[\"roi1_smoothed\"], label=\"ROI1 Pixels\", color=\"blue\", alpha=0.8)\n",
        "ax1.plot(filtered_df[\"timestamp\"], filtered_df[\"roi2_smoothed\"], label=\"ROI2 Pixels\", color=\"green\", alpha=0.8)\n",
        "ax1.set_ylabel(\"ROI Pixel Values\", fontsize=14)\n",
        "ax1.set_xlabel(\"Image Timestamp\", fontsize=14)\n",
        "ax1.tick_params(axis='y', labelcolor='black', labelsize=12)\n",
        "ax1.tick_params(axis='x', labelsize=12)\n",
        "ax1.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(filtered_df[\"timestamp\"], filtered_df[\"Stage\"], label=\"LRO Stage (cm)\", color=\"red\", linestyle=\"--\", alpha=0.7)\n",
        "ax2.set_ylabel(\"Stage (cm)\", fontsize=14)\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=12)\n",
        "ax2.legend(loc=\"upper right\", fontsize=12)\n",
        "\n",
        "plt.title(\"Time Series After IQR-Based Outlier Removal (ROI1 and ROI2 vs Stage)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"timeseries_stage.png\", dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CChbCSGiI8Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyJ9fbs9pYxN"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set style for aesthetics\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot IoU distribution (excluding NaN)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(\n",
        "    filtered_df[\"iou_score\"].dropna(),\n",
        "    bins=50,\n",
        "    kde=True,\n",
        "    color=\"skyblue\",\n",
        "    edgecolor=\"black\"\n",
        ")\n",
        "\n",
        "plt.title(\"Distribution of IoU Scores\", fontsize=16)\n",
        "plt.xlabel(\"IoU Score\", fontsize=14)\n",
        "plt.ylabel(\"Frequency\", fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISPl_RsYvYAs"
      },
      "outputs": [],
      "source": [
        "# Subset the relevant columns\n",
        "corr_df = filtered_df[[\"roi1_smoothed\", \"roi2_smoothed\", \"Stage\"]].dropna()\n",
        "corr_df.columns = [\"ROI1\", \"ROI2\", \"Stage\"]\n",
        "\n",
        "# Pearson correlation\n",
        "pearson_corr = corr_df.corr(method=\"pearson\")\n",
        "print(\"ðŸ“Œ Pearson Correlation Matrix:\")\n",
        "print(pearson_corr)\n",
        "\n",
        "# Spearman correlation\n",
        "spearman_corr = corr_df.corr(method=\"spearman\")\n",
        "print(\"\\nðŸ“Œ Spearman Correlation Matrix:\")\n",
        "print(spearman_corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_6pN8USv0jU"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Pearson\n",
        "sns.heatmap(\n",
        "    pearson_corr,\n",
        "    annot=True,\n",
        "    cmap=\"coolwarm\",\n",
        "    vmin=-1, vmax=1,\n",
        "    ax=axes[0],\n",
        "    annot_kws={\"size\": 12},  # annotation font size\n",
        "    cbar_kws={\"shrink\": 0.8}\n",
        ")\n",
        "axes[0].set_title(\"Pearson Correlation\", fontsize=14)\n",
        "axes[0].tick_params(axis='both', labelsize=12)\n",
        "\n",
        "# Spearman\n",
        "sns.heatmap(\n",
        "    spearman_corr,\n",
        "    annot=True,\n",
        "    cmap=\"coolwarm\",\n",
        "    vmin=-1, vmax=1,\n",
        "    ax=axes[1],\n",
        "    annot_kws={\"size\": 12},\n",
        "    cbar_kws={\"shrink\": 0.8}\n",
        ")\n",
        "axes[1].set_title(\"Spearman Correlation\", fontsize=14)\n",
        "axes[1].tick_params(axis='both', labelsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"correlation_stage.png\", dpi=300, bbox_inches='tight')  # save as PNG\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7dPaetjv8kG"
      },
      "outputs": [],
      "source": [
        "# 1. Prepare IQR-filtered data\n",
        "iqr_filtered_df = filtered_df[[\"roi1_smoothed\", \"roi2_smoothed\", \"Stage\"]].dropna()\n",
        "iqr_filtered_df.columns = [\"ROI1 Pixel Count\", \"ROI2 Pixel Count\", \"Stage (cm)\"]\n",
        "\n",
        "# 2. EDA Summary\n",
        "eda_summary = {\n",
        "    \"Total Entries\": len(iqr_filtered_df),\n",
        "    \"ROI1 Range\": (iqr_filtered_df[\"ROI1\"].min(), iqr_filtered_df[\"ROI1\"].max()),\n",
        "    \"ROI2 Range\": (iqr_filtered_df[\"ROI2\"].min(), iqr_filtered_df[\"ROI2\"].max()),\n",
        "    \"Stage Range\": (iqr_filtered_df[\"Stage\"].min(), iqr_filtered_df[\"Stage\"].max()),\n",
        "    \"Mean ROI1\": iqr_filtered_df[\"ROI1\"].mean(),\n",
        "    \"Mean ROI2\": iqr_filtered_df[\"ROI2\"].mean(),\n",
        "    \"Mean Stage\": iqr_filtered_df[\"Stage\"].mean(),\n",
        "    \"STD ROI1\": iqr_filtered_df[\"ROI1\"].std(),\n",
        "    \"STD ROI2\": iqr_filtered_df[\"ROI2\"].std(),\n",
        "    \"STD Stage\": iqr_filtered_df[\"Stage\"].std(),\n",
        "    \"Skewness ROI1\": iqr_filtered_df[\"ROI1\"].skew(),\n",
        "    \"Skewness ROI2\": iqr_filtered_df[\"ROI2\"].skew(),\n",
        "    \"Skewness Stage\": iqr_filtered_df[\"Stage\"].skew(),\n",
        "    \"Kurtosis ROI1\": iqr_filtered_df[\"ROI1\"].kurtosis(),\n",
        "    \"Kurtosis ROI2\": iqr_filtered_df[\"ROI2\"].kurtosis(),\n",
        "    \"Kurtosis Stage\": iqr_filtered_df[\"Stage\"].kurtosis()\n",
        "}\n",
        "\n",
        "# Print summary if desired\n",
        "for k, v in eda_summary.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "# 3. Pairplot\n",
        "sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.2)\n",
        "\n",
        "# Plot the pairwise relationships\n",
        "pairplot = sns.pairplot(\n",
        "    iqr_filtered_df,\n",
        "    kind=\"scatter\",\n",
        "    corner=True,\n",
        "    diag_kind=\"kde\",  # Use smooth KDE instead of hist\n",
        "    plot_kws={\"alpha\": 0.5, \"s\": 20, \"edgecolor\": \"k\"},\n",
        "    height=2.8,\n",
        "    aspect=1.1,\n",
        "    palette=\"muted\"\n",
        ")\n",
        "\n",
        "# Set the main title\n",
        "pairplot.fig.suptitle(\"Pairwise Feature Distributions and Relationships\", fontsize=16, y=1.02)\n",
        "\n",
        "# Improve axis label fonts\n",
        "for ax in pairplot.axes.flat:\n",
        "    if ax is not None:\n",
        "        ax.tick_params(axis='both', labelsize=11)\n",
        "        ax.xaxis.label.set_size(12)\n",
        "        ax.yaxis.label.set_size(12)\n",
        "\n",
        "# Remove unnecessary top/right spines for a cleaner look\n",
        "sns.despine()\n",
        "\n",
        "# Save and show\n",
        "pairplot.savefig(\"pairwise_distribution.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EOAzVmuxre6"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    return df[(df[column] >= Q1 - 1.5 * IQR) & (df[column] <= Q3 + 1.5 * IQR)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLIwojmeyZni"
      },
      "outputs": [],
      "source": [
        "# Fix: explicitly remove outliers on the correct column\n",
        "iqr_filtered_df = filtered_df.copy()\n",
        "iqr_filtered_df = remove_outliers_iqr(iqr_filtered_df, \"roi1_smoothed\")\n",
        "iqr_filtered_df = remove_outliers_iqr(iqr_filtered_df, \"roi2_smoothed\")\n",
        "iqr_filtered_df = remove_outliers_iqr(iqr_filtered_df, \"Stage\")\n",
        "\n",
        "# Sanity fix: explicitly convert Stage_ft into a clean Stage column\n",
        "iqr_filtered_df[\"Stage\"] = iqr_filtered_df[\"Stage\"].values  # overwrite with clean flat series\n",
        "\n",
        "# Then drop the Stage_ft column if you want\n",
        "#iqr_filtered_df = iqr_filtered_df.drop(columns=[\"Stage_ft\"])\n",
        "\n",
        "# Rename for plotting\n",
        "iqr_filtered_df = iqr_filtered_df.rename(columns={\n",
        "    \"roi1_smoothed\": \"ROI1\",\n",
        "    \"roi2_smoothed\": \"ROI2\",\n",
        "    \"Stage\": \"Stage\"\n",
        "})\n",
        "\n",
        "iqr_filtered_df = iqr_filtered_df.drop(columns=[\"ROI1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYvhWN-FyeFm"
      },
      "outputs": [],
      "source": [
        "# 2. EDA Summary\n",
        "eda_summary = {\n",
        "    \"Total Entries\": len(iqr_filtered_df),\n",
        "    \"ROI2 Range\": (iqr_filtered_df[\"ROI2\"].min(), iqr_filtered_df[\"ROI2\"].max()),\n",
        "    \"Stage Range\": (iqr_filtered_df[\"Stage\"].min(), iqr_filtered_df[\"Stage\"].max()),\n",
        "    \"Mean ROI2\": iqr_filtered_df[\"ROI2\"].mean(),\n",
        "    \"Mean Stage\": iqr_filtered_df[\"Stage\"].mean(),\n",
        "    \"STD ROI2\": iqr_filtered_df[\"ROI2\"].std(),\n",
        "    \"STD Stage\": iqr_filtered_df[\"Stage\"].std(),\n",
        "    \"Skewness ROI2\": iqr_filtered_df[\"ROI2\"].skew(),\n",
        "    \"Skewness Stage\": iqr_filtered_df[\"Stage\"].skew(),\n",
        "    \"Kurtosis ROI2\": iqr_filtered_df[\"ROI2\"].kurtosis(),\n",
        "    \"Kurtosis Stage\": iqr_filtered_df[\"Stage\"].kurtosis()\n",
        "}\n",
        "\n",
        "# Print summary if desired\n",
        "for k, v in eda_summary.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "# 3. Pairplot (fix the fig assignment)\n",
        "sns.set_style(\"white\")  # removes grid lines\n",
        "# Rename for clear axis labeling\n",
        "iqr_filtered_df_renamed = iqr_filtered_df.rename(columns={\n",
        "    \"ROI2\": \"ROI2 Pixel Counts\",\n",
        "    \"Stage\": \"Stage (cm)\"\n",
        "})\n",
        "\n",
        "# Create pairplot\n",
        "pairplot = sns.pairplot(\n",
        "    iqr_filtered_df_renamed[[\"ROI2 Pixel Counts\", \"Stage (cm)\"]],\n",
        "    corner=True,\n",
        "    plot_kws={\"alpha\": 0.4, \"s\": 25},\n",
        "    height=2.5\n",
        ")\n",
        "\n",
        "# Set title with larger font\n",
        "pairplot.fig.suptitle(\"Pairwise Feature Distributions and Relationships\", fontsize=14, y=1.03)\n",
        "\n",
        "# Update font size for all axes in the pairplot\n",
        "for ax in pairplot.axes.flat:\n",
        "    if ax is not None:\n",
        "        ax.grid(False)  # turns off grid\n",
        "        sns.despine(ax=ax)  # removes top/right spines\n",
        "        ax.tick_params(axis='both', labelsize=12)\n",
        "        ax.xaxis.label.set_size(13)\n",
        "        ax.yaxis.label.set_size(13)\n",
        "\n",
        "# Save figure\n",
        "pairplot.savefig(\"pairwise_distribution.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLkQKDnAygtb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# === Step 1: Prepare features and target ===\n",
        "X = iqr_filtered_df[[\"ROI2\"]]\n",
        "y = iqr_filtered_df[\"Stage\"]  # already cleaned and in feet\n",
        "timestamps = iqr_filtered_df[\"timestamp\"]\n",
        "\n",
        "# === Step 2: Train-Test Split (80/20) ===\n",
        "X_train, X_test, y_train, y_test, ts_train, ts_test = train_test_split(\n",
        "    X, y, timestamps, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 3: Fit model on training data ===\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# === Step 4: Predict on train and test sets ===\n",
        "y_train_pred = lin_reg.predict(X_train)\n",
        "y_test_pred = lin_reg.predict(X_test)\n",
        "\n",
        "# === Step 5: Compute train-test metrics ===\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# === Step 6: 5-Fold Cross-Validation ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "r2_scores = cross_val_score(lin_reg, X, y, cv=kf, scoring=\"r2\")\n",
        "neg_mse_scores = cross_val_score(lin_reg, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
        "rmse_scores = np.sqrt(-neg_mse_scores)\n",
        "\n",
        "# === Step 7: Summarize results ===\n",
        "results = {\n",
        "    \"Train RÂ²\": train_r2,\n",
        "    \"Test RÂ²\": test_r2,\n",
        "    \"Train RMSE\": train_rmse,\n",
        "    \"Test RMSE\": test_rmse,\n",
        "    \"Train MAE\": train_mae,\n",
        "    \"Test MAE\": test_mae,\n",
        "    \"CV RÂ² Mean\": np.mean(r2_scores),\n",
        "    \"CV RÂ² Std\": np.std(r2_scores),\n",
        "    \"CV RMSE Mean\": np.mean(rmse_scores),\n",
        "    \"CV RMSE Std\": np.std(rmse_scores),\n",
        "}\n",
        "\n",
        "# === Step 8: Display\n",
        "for k, v in results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHwfAbNj3cOR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# === Step 1: Polynomial Feature Expansion (Degree 2, ROI2 only) ===\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train[[\"ROI2\"]])\n",
        "X_test_poly = poly.transform(X_test[[\"ROI2\"]])\n",
        "X_full_poly = poly.transform(X[[\"ROI2\"]])  # for cross-validation\n",
        "\n",
        "# Optional: see generated features\n",
        "# print(poly.get_feature_names_out([\"ROI2\"]))\n",
        "\n",
        "# === Step 2: Train Model ===\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_poly, y_train)\n",
        "\n",
        "# === Step 3: Predictions ===\n",
        "y_train_pred = model.predict(X_train_poly)\n",
        "y_test_pred = model.predict(X_test_poly)\n",
        "\n",
        "# === Step 4: Train-Test Metrics ===\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(model, X_full_poly, y, cv=kf, scoring=\"r2\")\n",
        "cv_neg_mse = cross_val_score(model, X_full_poly, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
        "cv_rmse = np.sqrt(-cv_neg_mse)\n",
        "\n",
        "# === Step 6: Combine Metrics ===\n",
        "metrics_poly = {\n",
        "    \"Train RÂ²\": train_r2,\n",
        "    \"Test RÂ²\": test_r2,\n",
        "    \"Train RMSE\": train_rmse,\n",
        "    \"Test RMSE\": test_rmse,\n",
        "    \"Train MAE\": train_mae,\n",
        "    \"Test MAE\": test_mae,\n",
        "    \"CV RÂ² Mean\": np.mean(cv_r2),\n",
        "    \"CV RÂ² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse),\n",
        "}\n",
        "\n",
        "# === Step 7: Print Results Nicely ===\n",
        "print(\"\\nðŸ”¢ Polynomial Regression Results (Degree = 2, ROI2 only):\")\n",
        "for k, v in metrics_poly.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)  # should be (n,)\n",
        "print(type(y_train))"
      ],
      "metadata": {
        "id": "lY_ywcw5QW8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QLdKMx23xZu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define global axis limits with margin\n",
        "buffer = 0.05 * (y.max() - y.min())\n",
        "min_val = min(y.min(), y_train_pred.min(), y_test_pred.min()) - buffer\n",
        "max_val = max(y.max(), y_train_pred.max(), y_test_pred.max()) + buffer\n",
        "\n",
        "# Fit regression lines manually\n",
        "train_slope, train_intercept = np.polyfit(y_train, y_train_pred, 1)\n",
        "test_slope, test_intercept = np.polyfit(y_test, y_test_pred, 1)\n",
        "x_line = np.linspace(min_val, max_val, 100)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Train set\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.6, color='dodgerblue', edgecolor='k', s=50, label='Predictions')\n",
        "plt.plot(x_line, x_line, 'r--', linewidth=1.5, label='1:1 Line')\n",
        "plt.plot(x_line, train_slope * x_line + train_intercept, 'b-', linewidth=2, label='Regression Line')\n",
        "plt.title(\"Train Set: Actual vs Predicted Stage\", fontsize=14)\n",
        "plt.xlabel(\"Actual Stage (ft)\", fontsize=12)\n",
        "plt.ylabel(\"Predicted Stage (ft)\", fontsize=12)\n",
        "plt.xlim(min_val, max_val)\n",
        "plt.ylim(min_val, max_val)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=11)\n",
        "plt.tick_params(labelsize=11)\n",
        "\n",
        "# Test set\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.6, color='forestgreen', edgecolor='k', s=50, label='Predictions')\n",
        "plt.plot(x_line, x_line, 'r--', linewidth=1.5, label='1:1 Line')\n",
        "plt.plot(x_line, test_slope * x_line + test_intercept, 'g-', linewidth=2, label='Regression Line')\n",
        "plt.title(\"Test Set: Actual vs Predicted Stage\", fontsize=14)\n",
        "plt.xlabel(\"Actual Stage (ft)\", fontsize=12)\n",
        "plt.ylabel(\"Predicted Stage (ft)\", fontsize=12)\n",
        "plt.xlim(min_val, max_val)\n",
        "plt.ylim(min_val, max_val)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=11)\n",
        "plt.tick_params(labelsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"scatter_stage.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AVzPVLJ34GU"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# === Step 3: Tuned Random Forest Regressor ===\n",
        "rf_tuned = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42\n",
        ")\n",
        "rf_tuned.fit(X_train, y_train)\n",
        "\n",
        "# === Step 4: Predictions ===\n",
        "y_train_pred = rf_tuned.predict(X_train)\n",
        "y_test_pred = rf_tuned.predict(X_test)\n",
        "\n",
        "# === Step 5: Evaluation ===\n",
        "metrics_rf = {\n",
        "    \"Train RÂ²\": r2_score(y_train, y_train_pred),\n",
        "    \"Test RÂ²\": r2_score(y_test, y_test_pred),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred),\n",
        "}\n",
        "\n",
        "# === Step 6: Optional Cross-Validation (on full set) ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(rf_tuned, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(rf_tuned, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "metrics_rf.update({\n",
        "    \"CV RÂ² Mean\": np.mean(cv_r2),\n",
        "    \"CV RÂ² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse),\n",
        "})\n",
        "\n",
        "# === Step 7: Display nicely ===\n",
        "for k, v in metrics_rf.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FvpUPyL4JEP"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# === Step 1: Define XGBoost Regressor ===\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='reg:squarederror',  # prevents warning for regression\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === Step 2: Train on Train Set ===\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# === Step 3: Predict ===\n",
        "y_train_pred_xgb = xgb_model.predict(X_train)\n",
        "y_test_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# === Step 4: Train-Test Evaluation ===\n",
        "xgb_metrics = {\n",
        "    \"Train RÂ²\": r2_score(y_train, y_train_pred_xgb),\n",
        "    \"Test RÂ²\": r2_score(y_test, y_test_pred_xgb),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred_xgb),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred_xgb),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred_xgb)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred_xgb)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred_xgb),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred_xgb)\n",
        "}\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(xgb_model, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(xgb_model, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "xgb_metrics.update({\n",
        "    \"CV RÂ² Mean\": np.mean(cv_r2),\n",
        "    \"CV RÂ² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse)\n",
        "})\n",
        "\n",
        "# === Step 6: Print Clean Summary ===\n",
        "for k, v in xgb_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define global axis limits with margin\n",
        "buffer = 0.05 * (y.max() - y.min())\n",
        "min_val = min(y.min(), y_train_pred.min(), y_test_pred.min()) - buffer\n",
        "max_val = max(y.max(), y_train_pred.max(), y_test_pred.max()) + buffer\n",
        "\n",
        "# Fit regression lines manually\n",
        "train_slope, train_intercept = np.polyfit(y_train, y_train_pred, 1)\n",
        "test_slope, test_intercept = np.polyfit(y_test, y_test_pred, 1)\n",
        "x_line = np.linspace(min_val, max_val, 100)\n",
        "\n",
        "# Format equations\n",
        "train_eqn = f\"y = {train_slope:.2f}x + {train_intercept:.2f}\"\n",
        "test_eqn = f\"y = {test_slope:.2f}x + {test_intercept:.2f}\"\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Train set\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.6, color='dodgerblue', edgecolor='k', s=50, label='Predictions')\n",
        "plt.plot(x_line, x_line, 'r--', linewidth=1.5, label='1:1 Line')\n",
        "plt.plot(x_line, train_slope * x_line + train_intercept, 'b-', linewidth=2, label=f\"Regression Line\\n({train_eqn})\")\n",
        "plt.title(\"Train Set: Actual vs Predicted Stage\", fontsize=14)\n",
        "plt.xlabel(\"Actual Stage (cm)\", fontsize=12)\n",
        "plt.ylabel(\"Predicted Stage (cm)\", fontsize=12)\n",
        "plt.xlim(min_val, max_val)\n",
        "plt.ylim(min_val, max_val)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=11)\n",
        "plt.tick_params(labelsize=11)\n",
        "\n",
        "# Test set\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.6, color='forestgreen', edgecolor='k', s=50, label='Predictions')\n",
        "plt.plot(x_line, x_line, 'r--', linewidth=1.5, label='1:1 Line')\n",
        "plt.plot(x_line, test_slope * x_line + test_intercept, 'g-', linewidth=2, label=f\"Regression Line\\n({test_eqn})\")\n",
        "plt.title(\"Test Set: Actual vs Predicted Stage\", fontsize=14)\n",
        "plt.xlabel(\"Actual Stage (cm)\", fontsize=12)\n",
        "plt.ylabel(\"Predicted Stage (cm)\", fontsize=12)\n",
        "plt.xlim(min_val, max_val)\n",
        "plt.ylim(min_val, max_val)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=11)\n",
        "plt.tick_params(labelsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"scatter_stage.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pDu64DqYPL8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)"
      ],
      "metadata": {
        "id": "tk739zm-U9bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9mSxUdJ4aE1"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# === Step 1: Define LightGBM Regressor ===\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === Step 2: Train ===\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# === Step 3: Predict ===\n",
        "y_train_pred_lgb = lgb_model.predict(X_train)\n",
        "y_test_pred_lgb = lgb_model.predict(X_test)\n",
        "\n",
        "# === Step 4: Evaluate on Train and Test ===\n",
        "lgb_metrics = {\n",
        "    \"Train RÂ²\": r2_score(y_train, y_train_pred_lgb),\n",
        "    \"Test RÂ²\": r2_score(y_test, y_test_pred_lgb),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred_lgb),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred_lgb),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred_lgb)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred_lgb)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred_lgb),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred_lgb)\n",
        "}\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(lgb_model, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(lgb_model, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "lgb_metrics.update({\n",
        "    \"CV RÂ² Mean\": np.mean(cv_r2),\n",
        "    \"CV RÂ² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse)\n",
        "})\n",
        "\n",
        "# === Step 6: Print Results ===\n",
        "for k, v in lgb_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TikA5Rl4gWk"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjD6kq484lov"
      },
      "outputs": [],
      "source": [
        "# === Step 2: Define SVR Pipeline ===\n",
        "svr_model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.01)\n",
        ")\n",
        "\n",
        "# === Step 3: Train and Predict ===\n",
        "svr_model.fit(X_train, y_train)\n",
        "y_train_pred_svr = svr_model.predict(X_train)\n",
        "y_test_pred_svr = svr_model.predict(X_test)\n",
        "\n",
        "# === Step 4: Evaluation Metrics ===\n",
        "svr_metrics = {\n",
        "    \"Train RÂ²\": r2_score(y_train, y_train_pred_svr),\n",
        "    \"Test RÂ²\": r2_score(y_test, y_test_pred_svr),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred_svr),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred_svr),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred_svr)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred_svr)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred_svr),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred_svr)\n",
        "}\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(svr_model, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(svr_model, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "svr_metrics.update({\n",
        "    \"CV RÂ² Mean\": np.mean(cv_r2),\n",
        "    \"CV RÂ² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse)\n",
        "})\n",
        "\n",
        "# === Step 6: Print Results ===\n",
        "for k, v in svr_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCHRvfpg4nFh"
      },
      "outputs": [],
      "source": [
        "# === Step 1: Combine all model metrics into a dictionary ===\n",
        "model_results = {\n",
        "    #\"SVR\": svr_metrics,\n",
        "    \"Random Forest\": metrics_rf,\n",
        "    \"XGBoost\": xgb_metrics,\n",
        "    \"LightGBM\": lgb_metrics,\n",
        "    \"Polynomial Regression (d=2)\": metrics_poly,\n",
        "    \"Linear Regression\": results\n",
        "}\n",
        "\n",
        "# === Step 2: Create DataFrame ===\n",
        "ranking_df = pd.DataFrame(model_results).T[[\n",
        "    \"Test RÂ²\", \"Test MAE\", \"Test RMSE\", \"CV RÂ² Mean\", \"CV RMSE Mean\"\n",
        "]]\n",
        "ranking_df.columns = [\"RÂ²\", \"MAE\", \"RMSE\", \"CV_RÂ²\", \"CV_RMSE\"]\n",
        "\n",
        "# === Step 3: Rank models (lower rank is better) ===\n",
        "ranking_df[\"RÂ²_rank\"] = ranking_df[\"RÂ²\"].rank(ascending=False)\n",
        "ranking_df[\"MAE_rank\"] = ranking_df[\"MAE\"].rank(ascending=True)\n",
        "ranking_df[\"RMSE_rank\"] = ranking_df[\"RMSE\"].rank(ascending=True)\n",
        "ranking_df[\"CV_RÂ²_rank\"] = ranking_df[\"CV_RÂ²\"].rank(ascending=False)\n",
        "ranking_df[\"CV_RMSE_rank\"] = ranking_df[\"CV_RMSE\"].rank(ascending=True)\n",
        "\n",
        "# === Step 4: Calculate average rank and sort ===\n",
        "ranking_df[\"Avg_Rank\"] = ranking_df[\n",
        "    [\"RÂ²_rank\", \"MAE_rank\", \"RMSE_rank\", \"CV_RÂ²_rank\", \"CV_RMSE_rank\"]\n",
        "].mean(axis=1)\n",
        "\n",
        "ranking_df = ranking_df.sort_values(\"Avg_Rank\")\n",
        "\n",
        "# Display or save\n",
        "print(ranking_df[[\"RÂ²\", \"MAE\", \"RMSE\", \"CV_RÂ²\", \"CV_RMSE\", \"Avg_Rank\"]])\n",
        "# ranking_df.to_csv(\"model_ranking.csv\", index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === STEP 1: Predictions from the top 3 models ===\n",
        "# Ensure these variables are already computed\n",
        "pred_xgb = y_test_pred_xgb      # XGBoost\n",
        "pred_lgb = y_test_pred_lgb      # LightGBM\n",
        "pred_rf  = y_test_pred       # Random Forest\n",
        "\n",
        "# === STEP 2: Create stacked combinations ===\n",
        "stack_xgb_rf   = np.vstack([pred_xgb, pred_rf]).T\n",
        "stack_xgb_lgb  = np.vstack([pred_xgb, pred_lgb]).T\n",
        "stack_rf_lgb   = np.vstack([pred_rf, pred_lgb]).T\n",
        "stack_all_3    = np.vstack([pred_xgb, pred_lgb, pred_rf]).T\n",
        "\n",
        "# === STEP 3: Meta-model (stacked ensemble) predictions ===\n",
        "stacked_xgb_rf   = LinearRegression().fit(stack_xgb_rf, y_test).predict(stack_xgb_rf)\n",
        "stacked_xgb_lgb  = LinearRegression().fit(stack_xgb_lgb, y_test).predict(stack_xgb_lgb)\n",
        "stacked_rf_lgb   = LinearRegression().fit(stack_rf_lgb, y_test).predict(stack_rf_lgb)\n",
        "stacked_all_3    = LinearRegression().fit(stack_all_3, y_test).predict(stack_all_3)\n",
        "\n",
        "# === STEP 4: Simple averages ===\n",
        "avg_xgb_rf   = np.mean(stack_xgb_rf, axis=1)\n",
        "avg_xgb_lgb  = np.mean(stack_xgb_lgb, axis=1)\n",
        "avg_rf_lgb   = np.mean(stack_rf_lgb, axis=1)\n",
        "avg_all_3    = np.mean(stack_all_3, axis=1)\n",
        "\n",
        "# === STEP 5: Weighted average (customizable weights) ===\n",
        "# You can tune these weights\n",
        "weighted_avg = 0.4 * pred_rf + 0.4 * pred_lgb + 0.2 * pred_xgb\n",
        "\n",
        "# === STEP 6: Evaluation function ===\n",
        "def evaluate(y_true, y_pred):\n",
        "    return {\n",
        "        \"RÂ²\": r2_score(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    }\n",
        "\n",
        "# === STEP 7: Compute metrics for all ensemble strategies ===\n",
        "ensemble_results = {\n",
        "    \"Simple Avg (XGB + RF)\": evaluate(y_test, avg_xgb_rf),\n",
        "    \"Simple Avg (XGB + LGB)\": evaluate(y_test, avg_xgb_lgb),\n",
        "    \"Simple Avg (RF + LGB)\": evaluate(y_test, avg_rf_lgb),\n",
        "    \"Simple Avg (All 3)\": evaluate(y_test, avg_all_3),\n",
        "    \"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\": evaluate(y_test, weighted_avg),\n",
        "    \"Stacked (XGB + RF)\": evaluate(y_test, stacked_xgb_rf),\n",
        "    \"Stacked (XGB + LGB)\": evaluate(y_test, stacked_xgb_lgb),\n",
        "    \"Stacked (RF + LGB)\": evaluate(y_test, stacked_rf_lgb),\n",
        "    \"Stacked (All 3)\": evaluate(y_test, stacked_all_3)\n",
        "}\n",
        "\n",
        "# === STEP 8: Convert to DataFrame and sort ===\n",
        "ensemble_df = pd.DataFrame(ensemble_results).T\n",
        "ensemble_df = ensemble_df.sort_values(\"RÂ²\", ascending=False)\n",
        "\n",
        "# Display the final ensemble comparison\n",
        "print(ensemble_df)\n",
        "\n",
        "# Optional: Save to CSV\n",
        "# ensemble_df.to_csv(\"ensemble_comparison_blacksmith.csv\", index=True)\n"
      ],
      "metadata": {
        "id": "GBuonMS2PttU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === BASE MODELS ===\n",
        "base_models = {\n",
        "    \"LGBM\": lgb_model,\n",
        "    \"Random Forest\": rf_tuned,\n",
        "    \"XGBoost\": xgb_model\n",
        "}\n",
        "\n",
        "# === PREPARE OOF PREDICTIONS ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "oof_preds = {name: np.zeros_like(y_train) for name in base_models}\n",
        "test_preds = {name: [] for name in base_models}\n",
        "\n",
        "# === 1. Generate OOF for training and test predictions ===\n",
        "for train_idx, val_idx in kf.split(X_train):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    for name, model in base_models.items():\n",
        "        model.fit(X_tr, y_tr)\n",
        "        oof_preds[name][val_idx] = model.predict(X_val)\n",
        "        test_preds[name].append(model.predict(X_test))  # accumulate fold predictions\n",
        "\n",
        "# === 2. Stack into new training and test matrices ===\n",
        "X_meta_train = np.vstack([oof_preds[name] for name in base_models]).T\n",
        "X_meta_test = np.mean([np.vstack(test_preds[name]) for name in base_models], axis=1).T\n",
        "\n",
        "# === 3. Train meta-model on OOF predictions ===\n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(X_meta_train, y_train)\n",
        "\n",
        "# === 4. Predict on holdout test set ===\n",
        "meta_pred_test = meta_model.predict(X_meta_test)\n",
        "\n",
        "# === 5. Evaluate final stacked model ===\n",
        "def evaluate(y_true, y_pred):\n",
        "    return {\n",
        "        \"RÂ²\": r2_score(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    }\n",
        "\n",
        "stacked_cv_results = evaluate(y_test, meta_pred_test)\n",
        "print(\"Cross-Validated Stacked Ensemble Performance:\")\n",
        "for k, v in stacked_cv_results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "1JmleamKP2Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# === Set global font ===\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.rcParams['legend.fontsize'] = 14\n",
        "\n",
        "# === Prepare data for plotting ===\n",
        "df_plot = pd.DataFrame({\n",
        "    \"timestamp\": ts_test,\n",
        "    \"True Stage\": y_test,\n",
        "    \"Simple Avg (XGB + RF + LGB)\": avg_all_3,\n",
        "    \"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\": weighted_avg,\n",
        "    \"Stacked Ensemble (All 3)\": stacked_all_3\n",
        "}).sort_values(\"timestamp\")\n",
        "\n",
        "# === Create subplots ===\n",
        "fig, axs = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
        "\n",
        "# Plot 1: Simple Average\n",
        "axs[0].plot(df_plot[\"timestamp\"], df_plot[\"True Stage\"], label=\"True Stage\", color=\"black\", linewidth=2)\n",
        "axs[0].plot(df_plot[\"timestamp\"], df_plot[\"Simple Avg (XGB + RF + LGB)\"], label=\"Simple Average\", color=\"royalblue\", linewidth=2, alpha=0.7)\n",
        "axs[0].set_title(\"Simple Average (XGB + RF + LGB) vs. True Stage\")\n",
        "axs[0].set_ylabel(\"Stage (cm)\", fontsize=14)\n",
        "axs[0].legend()\n",
        "axs[0].tick_params(axis='both', labelsize=14)\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot 2: Weighted Average\n",
        "axs[1].plot(df_plot[\"timestamp\"], df_plot[\"True Stage\"], label=\"True Stage\", color=\"black\", linewidth=2)\n",
        "axs[1].plot(df_plot[\"timestamp\"], df_plot[\"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\"], label=\"Weighted Average\", color=\"darkorange\", linewidth=2, alpha=0.7)\n",
        "axs[1].set_title(\"Weighted Average (0.4 RF + 0.4 LGB + 0.2 XGB) vs. True Stage\")\n",
        "axs[1].set_ylabel(\"Stage (cm)\", fontsize=14)\n",
        "axs[1].legend()\n",
        "axs[1].tick_params(axis='both', labelsize=14)\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot 3: Stacked Ensemble\n",
        "axs[2].plot(df_plot[\"timestamp\"], df_plot[\"True Stage\"], label=\"True Stage\", color=\"black\", linewidth=2)\n",
        "axs[2].plot(df_plot[\"timestamp\"], df_plot[\"Stacked Ensemble (All 3)\"], label=\"Stacked Ensemble\", color=\"seagreen\", linewidth=2, alpha=0.7)\n",
        "axs[2].set_title(\"Stacked Ensemble (XGB + RF + LGB) vs. True Stage\")\n",
        "axs[2].set_xlabel(\"Timestamp\", fontsize=14)\n",
        "axs[2].set_ylabel(\"Stage (cm)\", fontsize=14)\n",
        "axs[2].legend()\n",
        "axs[2].tick_params(axis='both', labelsize=14)\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# === Save the figure ===\n",
        "plt.savefig(\"ensemble_stage_predictions.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sB5jL8jXQb_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# === Create subplots ===\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# Titles and predictions\n",
        "titles = [\n",
        "    \"Simple Avg (XGB + RF + LGB)\",\n",
        "    \"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\",\n",
        "    \"Stacked Ensemble (All 3)\"\n",
        "]\n",
        "predictions = [avg_all_3, weighted_avg, stacked_all_3]\n",
        "\n",
        "# === Plot each ensemble prediction vs. actual stage ===\n",
        "for ax, title, pred in zip(axs, titles, predictions):\n",
        "    # Scatter plot\n",
        "    ax.scatter(y_test, pred, alpha=0.7, edgecolors='k')\n",
        "\n",
        "    # 1:1 Line\n",
        "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"1:1 Line\")\n",
        "\n",
        "    # Regression line\n",
        "    coeffs = np.polyfit(y_test, pred, deg=1)\n",
        "    reg_line = np.poly1d(coeffs)\n",
        "    ax.plot(y_test, reg_line(y_test), color='blue', linewidth=2, label=\"Regression Line\")\n",
        "\n",
        "    # Labels and formatting\n",
        "    ax.set_xlabel(\"Actual Stage (cm)\", fontsize=14)\n",
        "    ax.set_title(title, fontsize=15)\n",
        "    ax.tick_params(axis='both', labelsize=14)\n",
        "    ax.legend()\n",
        "\n",
        "# Shared Y-axis label\n",
        "axs[0].set_ylabel(\"Predicted Stage (cm)\", fontsize=14)\n",
        "\n",
        "# Main title\n",
        "fig.suptitle(\"Actual vs Predicted Stage (Top Ensemble Models)\", fontsize=16)\n",
        "\n",
        "# Layout and save\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.savefig(\"ensemble_scatter_top3.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S1u2Uf86Q-bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Calculate Residuals ===\n",
        "resid_simple = y_test - avg_all_3\n",
        "resid_weighted = y_test - weighted_avg\n",
        "resid_stacked = y_test - stacked_all_3\n",
        "\n",
        "# === Create subplots ===\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# Titles and predictions\n",
        "titles = [\n",
        "    \"Simple Avg (XGB + RF + LGB)\",\n",
        "    \"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\",\n",
        "    \"Stacked Ensemble (All 3)\"\n",
        "]\n",
        "predictions = [avg_all_3, weighted_avg, stacked_all_3]\n",
        "residuals = [resid_simple, resid_weighted, resid_stacked]\n",
        "\n",
        "# === Plot residuals ===\n",
        "for ax, title, pred, resid in zip(axs, titles, predictions, residuals):\n",
        "    ax.scatter(pred, resid, alpha=0.7, edgecolors='k')\n",
        "    ax.axhline(0, color='red', linestyle='--')\n",
        "    ax.set_xlabel(\"Predicted Stage (cm)\", fontsize=14)\n",
        "    ax.set_title(\n",
        "        f\"{title}\\n$R^2$ = {r2_score(y_test, pred):.3f}, MAE = {mean_absolute_error(y_test, pred):.4f}\",\n",
        "        fontsize=13\n",
        "    )\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "\n",
        "# Shared Y-axis label\n",
        "axs[0].set_ylabel(\"Residual (Actual - Predicted) (cm)\", fontsize=14)\n",
        "\n",
        "# Layout and save\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"ensemble_residuals_top3.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GhPAoGSjRVsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Calculate Prediction Errors ===\n",
        "error_simple = avg_all_3 - y_test\n",
        "error_weighted = weighted_avg - y_test\n",
        "error_stacked = stacked_all_3 - y_test\n",
        "\n",
        "# === Create histograms of prediction errors ===\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# Titles and errors\n",
        "titles = [\n",
        "    \"Simple Avg (XGB + RF + LGB)\",\n",
        "    \"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\",\n",
        "    \"Stacked Ensemble (All 3)\"\n",
        "]\n",
        "errors = [error_simple, error_weighted, error_stacked]\n",
        "\n",
        "for ax, name, error in zip(axs, titles, errors):\n",
        "    ax.hist(error, bins=40, color='skyblue', edgecolor='black')\n",
        "    ax.axvline(0, color='red', linestyle='--')\n",
        "    ax.set_title(f\"{name} Error Histogram\", fontsize=14)\n",
        "    ax.set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "    ax.tick_params(axis='both', labelsize=14)\n",
        "\n",
        "# Shared Y-axis label\n",
        "axs[0].set_ylabel(\"Frequency\", fontsize=14)\n",
        "\n",
        "# Layout and optional save\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"ensemble_error_histogram_top3.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wg29gCpKRn53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_stage = y_test.values\n",
        "pred_simple = avg_all_3\n",
        "pred_weighted = weighted_avg\n",
        "pred_stacked = stacked_all_3\n",
        "\n",
        "# Summary metrics\n",
        "summary_metrics = pd.DataFrame({\n",
        "    \"Model\": [\"Simple Avg (2 models)\", \"Weighted Avg\", \"Stacked Ensemble (3 models)\"],\n",
        "    \"RÂ²\": [\n",
        "        r2_score(true_stage, pred_simple),\n",
        "        r2_score(true_stage, pred_weighted),\n",
        "        r2_score(true_stage, pred_stacked)\n",
        "    ],\n",
        "    \"MAE\": [\n",
        "        mean_absolute_error(true_stage, pred_simple),\n",
        "        mean_absolute_error(true_stage, pred_weighted),\n",
        "        mean_absolute_error(true_stage, pred_stacked)\n",
        "    ]\n",
        "})\n",
        "\n",
        "summary_metrics"
      ],
      "metadata": {
        "id": "4fz9qoRmR03o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bland-Altman plot function\n",
        "def bland_altman_plot(actual, predicted, model_name):\n",
        "    mean_values = (actual + predicted) / 2\n",
        "    diff = actual - predicted\n",
        "    mean_diff = np.mean(diff)\n",
        "    std_diff = np.std(diff)\n",
        "    upper_limit = mean_diff + 1.96 * std_diff\n",
        "    lower_limit = mean_diff - 1.96 * std_diff\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.scatter(mean_values, diff, alpha=0.6, edgecolors='k', color='cornflowerblue')\n",
        "    plt.axhline(mean_diff, color='red', linestyle='--', label=f'Mean Diff: {mean_diff:.3f}')\n",
        "    plt.axhline(upper_limit, color='grey', linestyle='--', label=f'+1.96 SD: {upper_limit:.3f}')\n",
        "    plt.axhline(lower_limit, color='grey', linestyle='--', label=f'-1.96 SD: {lower_limit:.3f}')\n",
        "    plt.fill_between(mean_values, lower_limit, upper_limit, color='grey', alpha=0.1)\n",
        "\n",
        "    plt.title(f'Bland-Altman Plot ({model_name})', fontsize=14)\n",
        "    plt.xlabel('Mean of Actual and Predicted Stage (cm)', fontsize=14)\n",
        "    plt.ylabel('Residual (Actual - Predicted) (cm)', fontsize=14)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True)\n",
        "    plt.tick_params(axis='both', labelsize=14)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig(f\"bland_altman_{model_name.lower().replace(' ', '_')}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Run for all three models\n",
        "for model_name, y_pred in zip(\n",
        "    [\"Simple Avg (SVR + RF)\", \"Weighted Avg\", \"Stacked Ensemble (All 3)\"],\n",
        "    [avg_all_3, weighted_avg, stacked_all_3]\n",
        "):\n",
        "    bland_altman_plot(y_test, y_pred, model_name)"
      ],
      "metadata": {
        "id": "nrmDygYNSFGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Function to plot residuals over time ===\n",
        "def plot_residuals_over_time(residuals_dict, timestamps):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    for label, resids in residuals_dict.items():\n",
        "        plt.plot(timestamps, resids, label=label, alpha=0.5)\n",
        "\n",
        "    plt.axhline(0, color='red', linestyle='--')\n",
        "    plt.title(\"Residuals Over Time\", fontsize=15)\n",
        "    plt.xlabel(\"Timestamp\", fontsize=13)\n",
        "    plt.ylabel(\"Residual (Actual - Predicted) (cm)\", fontsize=14)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True)\n",
        "    plt.tick_params(axis='both', labelsize=14)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig(\"ensemble_timeseries_residuals_top3.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# === Ensure timestamps are aligned with y_test ===\n",
        "timestamps_sorted = ts_test.sort_values().reset_index(drop=True)\n",
        "\n",
        "# === Residuals dictionary structure for top 3 ensemble models ===\n",
        "residuals_top3 = {\n",
        "    \"Simple Avg (XGB + RF + LGB)\": avg_all_3 - y_test,\n",
        "    \"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\": weighted_avg - y_test,\n",
        "    \"Stacked Ensemble (All 3)\": stacked_all_3 - y_test\n",
        "}\n",
        "\n",
        "# === Plot ===\n",
        "plot_residuals_over_time(residuals_dict=residuals_top3, timestamps=timestamps_sorted)\n"
      ],
      "metadata": {
        "id": "Uo6FVCcBSQyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Compute residuals ===\n",
        "residual_simple = y_test - avg_all_3\n",
        "residual_weighted = y_test - weighted_avg\n",
        "residual_stacked = y_test - stacked_all_3\n",
        "\n",
        "# === Create subplots ===\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# === Simple Avg plot ===\n",
        "sns.kdeplot(\n",
        "    residual_simple, ax=axes[0], fill=True,\n",
        "    color=\"#1f77b4\", alpha=0.5, linewidth=1\n",
        ")\n",
        "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=1.2)\n",
        "axes[0].set_title(\"Simple Avg (XGB + RF + LGB)\", fontsize=14)\n",
        "axes[0].set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "axes[0].set_ylabel(\"Density\", fontsize=14)\n",
        "axes[0].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "# === Weighted Avg plot ===\n",
        "sns.kdeplot(\n",
        "    residual_weighted, ax=axes[1], fill=True,\n",
        "    color=\"#ff7f0e\", alpha=0.4, linewidth=1\n",
        ")\n",
        "axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1.2)\n",
        "axes[1].set_title(\"Weighted Avg (0.4 RF + 0.4 LGB + 0.2 XGB)\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "axes[1].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "# === Stacked Ensemble plot ===\n",
        "sns.kdeplot(\n",
        "    residual_stacked, ax=axes[2], fill=True,\n",
        "    color=\"#2ca02c\", alpha=0.3, linewidth=1\n",
        ")\n",
        "axes[2].axvline(x=0, color='black', linestyle='--', linewidth=1.2)\n",
        "axes[2].set_title(\"Stacked Ensemble (All 3)\", fontsize=14)\n",
        "axes[2].set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "axes[2].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "# === Final layout ===\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"ensemble_error_kde_top3_separate.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hzn8K7HgS9wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Generate example residuals (replace with actual residuals in real case)\n",
        "np.random.seed(42)\n",
        "residual_simple = np.random.normal(loc=0, scale=0.1, size=100)\n",
        "residual_weighted = np.random.normal(loc=0, scale=0.08, size=100)\n",
        "residual_stacked = np.random.normal(loc=0, scale=0.07, size=100)\n",
        "\n",
        "# Create summary dataframe\n",
        "summary_stats = pd.DataFrame({\n",
        "    \"Model\": [\"Simple Avg (2)\", \"Weighted Avg\", \"Stacked Ensemble (3)\"],\n",
        "    \"Mean Error\": [residual_simple.mean(), residual_weighted.mean(), residual_stacked.mean()],\n",
        "    \"Std Dev\": [residual_simple.std(), residual_weighted.std(), residual_stacked.std()],\n",
        "    \"Skewness\": [skew(residual_simple), skew(residual_weighted), skew(residual_stacked)],\n",
        "    \"Kurtosis\": [kurtosis(residual_simple), kurtosis(residual_weighted), kurtosis(residual_stacked)]\n",
        "})\n",
        "summary_stats"
      ],
      "metadata": {
        "id": "WrK_CWizUMt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(lgb_model, \"lgb_model.pkl\")\n",
        "joblib.dump(rf_tuned, \"rf_model.pkl\")\n",
        "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
        "meta_model_3 = LinearRegression().fit(stack_all_3, y_test)\n",
        "joblib.dump(meta_model_3, \"stacked_meta_model.pkl\")\n"
      ],
      "metadata": {
        "id": "iqKGv3FTT7PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === Load Models ===\n",
        "lgb_model = joblib.load(\"lgb_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")         # rf_tuned saved here\n",
        "xgb_model = joblib.load(\"xgb_model.pkl\")\n",
        "meta_model_3 = joblib.load(\"stacked_meta_model.pkl\")\n",
        "\n",
        "# === Prediction Function (ROI2 only) ===\n",
        "def predict_stage_from_roi2(roi2):\n",
        "    \"\"\"\n",
        "    Predict water stage from ROI2 using stacked ensemble model.\n",
        "    \"\"\"\n",
        "    features = np.array([[roi2]])\n",
        "\n",
        "    # Base model predictions\n",
        "    pred_lgb = lgb_model.predict(features)[0]\n",
        "    pred_rf  = rf_model.predict(features)[0]\n",
        "    pred_xgb = xgb_model.predict(features)[0]\n",
        "\n",
        "    # Meta model prediction\n",
        "    stacked_input = np.array([[pred_lgb, pred_rf, pred_xgb]])\n",
        "    stage_prediction = meta_model_3.predict(stacked_input)[0]\n",
        "\n",
        "    return stage_prediction\n",
        "\n",
        "# === Predict for Full Dataset ===\n",
        "X_all = iqr_filtered_df[[\"ROI2\"]].copy()\n",
        "timestamps_all = iqr_filtered_df[\"timestamp\"]\n",
        "\n",
        "# Base model predictions\n",
        "y_pred_lgb_all = lgb_model.predict(X_all)\n",
        "y_pred_rf_all  = rf_model.predict(X_all)\n",
        "y_pred_xgb_all = xgb_model.predict(X_all)\n",
        "\n",
        "# Meta-model stacked prediction\n",
        "stacked_input_all = np.vstack([y_pred_lgb_all, y_pred_rf_all, y_pred_xgb_all]).T\n",
        "stage_pred_all = meta_model_3.predict(stacked_input_all)\n",
        "\n",
        "# Output DataFrame\n",
        "predicted_stage_df = pd.DataFrame({\n",
        "    \"timestamp\": timestamps_all.values,\n",
        "    \"ROI2\": X_all[\"ROI2\"].values,\n",
        "    \"predicted_stage\": stage_pred_all\n",
        "})\n",
        "\n",
        "predicted_stage_df.head()\n"
      ],
      "metadata": {
        "id": "_V1ldvf_U6_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sort by timestamp to ensure clean time series plot\n",
        "plot_df = predicted_stage_df.copy()\n",
        "plot_df[\"timestamp\"] = timestamps_all.values  # Ensure timestamp column exists\n",
        "plot_df[\"actual_stage\"] = iqr_filtered_df[\"Stage\"].values  # Replace with correct actual stage column if needed\n",
        "plot_df = plot_df.sort_values(\"timestamp\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(plot_df[\"timestamp\"], plot_df[\"actual_stage\"], label=\"Actual Stage\", color=\"black\", linewidth=2)\n",
        "plt.plot(plot_df[\"timestamp\"], plot_df[\"predicted_stage\"], label=\"Predicted Stage (Stacked Ensemble)\", color=\"seagreen\", linestyle='--', linewidth=2, alpha=0.7)\n",
        "\n",
        "# Labels and formatting\n",
        "plt.title(\"Predicted vs. Actual Water Stage\", fontsize=16)\n",
        "plt.xlabel(\"Timestamp\", fontsize=14)\n",
        "plt.ylabel(\"Stage (cm)\", fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.xticks()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save and show\n",
        "plt.savefig(\"predicted_vs_actual_stage.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mKspR98oWc3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only positive discharge and reasonable stage values\n",
        "filtered = iqr_filtered_df[(iqr_filtered_df[\"Discharge\"] > 0) & (iqr_filtered_df[\"Stage\"] > 0.1)].copy()\n",
        "\n",
        "# Extract arrays for curve fitting\n",
        "h = filtered[\"Stage\"].values\n",
        "Q = filtered[\"Discharge\"].values\n"
      ],
      "metadata": {
        "id": "zRYzTVuOZ19y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import curve_fit\n",
        "import numpy as np\n",
        "\n",
        "# Rating curve function\n",
        "def rating_curve(h, a, b, h0):\n",
        "    return a * np.maximum((h - h0), 0) ** b\n",
        "\n",
        "# Initial guess and curve fitting\n",
        "initial_guess = (1.0, 2.0, 0.5)\n",
        "popt, pcov = curve_fit(rating_curve, h, Q, p0=initial_guess, maxfev=10000)\n",
        "\n",
        "# Extract fitted parameters\n",
        "a, b, h0 = popt\n",
        "print(f\"Fitted Rating Curve Parameters:\\na = {a:.4f}, b = {b:.4f}, h0 = {h0:.4f}\")\n"
      ],
      "metadata": {
        "id": "Fe1Paw__YlEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "h_fit = np.linspace(h.min(), h.max(), 200)\n",
        "Q_fit = rating_curve(h_fit, *popt)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(h, Q, label=\"Observed Discharge\", color=\"black\", alpha=0.6)\n",
        "plt.plot(h_fit, Q_fit, label=\"Fitted Rating Curve\", color=\"red\", linewidth=2)\n",
        "plt.xlabel(\"Stage (cm)\")\n",
        "plt.ylabel(\"Discharge (cms)\")\n",
        "plt.title(\"Stage-Discharge Rating Curve\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"rating_curve.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aq-goBlxY9kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Define rating curve function ===\n",
        "def rating_curve(h, a=0.0310, b=1.2041, h0=6.6794):\n",
        "    return a * np.maximum((h - h0), 0) ** b\n",
        "\n",
        "# === 2. Apply to ensemble-predicted stage ===\n",
        "predicted_stage_df[\"predicted_discharge\"] = rating_curve(predicted_stage_df[\"predicted_stage\"])\n",
        "\n",
        "# === 3. Merge with actual discharge for comparison ===\n",
        "pred_discharge_df = pd.merge(\n",
        "    predicted_stage_df,\n",
        "    iqr_filtered_df[[\"timestamp\", \"Discharge\"]],\n",
        "    on=\"timestamp\",\n",
        "    how=\"inner\"\n",
        ").dropna(subset=[\"Discharge\", \"predicted_discharge\"])\n"
      ],
      "metadata": {
        "id": "uGqXLP5SZh0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# === Filter entire DataFrame where Discharge is valid ===\n",
        "valid_df = pred_discharge_df[pred_discharge_df[\"Discharge\"] != -9999.0].copy()\n",
        "\n",
        "# Now extract all aligned values from the same filtered DataFrame\n",
        "y_true = valid_df[\"Discharge\"]\n",
        "y_pred = valid_df[\"predicted_discharge\"]\n",
        "timestamps = valid_df[\"timestamp\"]\n",
        "\n",
        "# === Extract valid true and predicted values ===\n",
        "y_true = valid_df[\"Discharge\"]\n",
        "y_pred = valid_df[\"predicted_discharge\"]\n",
        "\n",
        "# === Compute Evaluation Metrics ===\n",
        "discharge_metrics = {\n",
        "    \"RÂ²\": r2_score(y_true, y_pred),\n",
        "    \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "    \"MAE\": mean_absolute_error(y_true, y_pred)\n",
        "}\n",
        "\n",
        "# === Display Results ===\n",
        "for k, v in discharge_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "PIXcwQcmakkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import savgol_filter\n",
        "y_pred_smooth = savgol_filter(y_pred, window_length=21, polyorder=2)\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Plot actual and predicted discharge\n",
        "plt.plot(timestamps, y_true, label=\"Observed Discharge\", linewidth=2)\n",
        "plt.plot(timestamps, y_pred_smooth, label=\"Predicted Discharge\", linestyle=\"--\", linewidth=2, alpha=0.9)\n",
        "\n",
        "# Labels and title\n",
        "plt.title(\"Predicted vs. Observed Discharge\", fontsize=16)\n",
        "plt.xlabel(\"Timestamp\", fontsize=14)\n",
        "plt.ylabel(\"Discharge (cms)\", fontsize=14)\n",
        "\n",
        "# Legend and grid\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# Save and show\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"predicted_vs_actual_discharge.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cYNhDTeUarHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove -9999 from either column\n",
        "clean_df = pred_discharge_df[\n",
        "    (pred_discharge_df[\"Discharge\"] != -9999) &\n",
        "    (pred_discharge_df[\"predicted_discharge\"] != -9999)\n",
        "]\n",
        "\n",
        "# Prepare values\n",
        "x = clean_df[\"Discharge\"].values.reshape(-1, 1)  # Observed\n",
        "y = clean_df[\"predicted_discharge\"].values       # Predicted\n",
        "\n",
        "# Fit regression line\n",
        "reg_model = LinearRegression()\n",
        "reg_model.fit(x, y)\n",
        "y_pred_line = reg_model.predict(x)\n",
        "\n",
        "# Create regression equation string\n",
        "slope = reg_model.coef_[0]\n",
        "intercept = reg_model.intercept_\n",
        "reg_eqn = f\"y = {slope:.2f}x + {intercept:.2f}\"\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.scatterplot(x=clean_df[\"Discharge\"], y=clean_df[\"predicted_discharge\"],\n",
        "                color='royalblue', edgecolor='k', alpha=0.6, s=60, label=\"Predictions\")\n",
        "\n",
        "# Plot 1:1 line\n",
        "lims = [min(x.min(), y.min()), max(x.max(), y.max())]\n",
        "plt.plot(lims, lims, 'r--', linewidth=2, label=\"1:1 Line\")\n",
        "\n",
        "# Regression line with equation\n",
        "plt.plot(x.flatten(), y_pred_line, color=\"seagreen\", linestyle='-', linewidth=2, label=f\"Regression Line\\n({reg_eqn})\")\n",
        "\n",
        "# Labels and styling\n",
        "plt.xlabel(\"Observed Discharge (cms)\", fontsize=14)\n",
        "plt.ylabel(\"Predicted Discharge (cms)\", fontsize=14)\n",
        "plt.title(\"Observed vs Predicted Discharge\", fontsize=16)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.legend(fontsize=12)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save\n",
        "plt.savefig(\"discharge_scatter.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZLqKpfVaatJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kBT1ElbldUuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}