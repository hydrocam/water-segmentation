{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV4FYU9xgnUd"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaevQPkwgnUf"
      },
      "outputs": [],
      "source": [
        "# Load ground truth data\n",
        "usgs_raw  = pd.read_csv(\"USGS_FD.csv\", sep=',')\n",
        "usgs_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbyo10WbgnUg"
      },
      "outputs": [],
      "source": [
        "# Load ROI data\n",
        "camera_raw = pd.read_csv(\"firstdamsite.csv\", sep=',')\n",
        "camera_raw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean USGS data (first row is header info)\n",
        "usgs_raw.columns = usgs_raw.iloc[0]\n",
        "usgs_cleaned = usgs_raw.iloc[1:].copy()\n",
        "usgs_cleaned.columns = usgs_raw.columns\n",
        "\n",
        "# Step 3: Rename relevant columns\n",
        "usgs_cleaned = usgs_cleaned.rename(columns={\n",
        "    '20d': 'datetime',\n",
        "    '14n': 'stage'\n",
        "})\n",
        "\n",
        "# Step 4: Convert datetime and stage to proper formats\n",
        "usgs_cleaned[\"datetime\"] = pd.to_datetime(usgs_cleaned[\"datetime\"], errors=\"coerce\")\n",
        "usgs_cleaned[\"stage\"] = pd.to_numeric(usgs_cleaned[\"stage\"], errors=\"coerce\")\n",
        "usgs_cleaned = usgs_cleaned.dropna(subset=[\"datetime\"])"
      ],
      "metadata": {
        "id": "E0DfEiCf0WTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Prepare camera dataset timestamps\n",
        "camera_raw[\"image_timestamp\"] = pd.to_datetime(camera_raw[\"image_timestamp\"], errors=\"coerce\")\n",
        "camera_raw[\"RoundedDateTime\"] = camera_raw[\"image_timestamp\"].dt.round(\"15min\")\n",
        "\n",
        "# Step 6: Select relevant USGS data and merge with camera data\n",
        "usgs_selected = usgs_cleaned[[\"datetime\", \"stage\"]]\n",
        "merged_data = camera_raw.merge(usgs_selected, left_on=\"RoundedDateTime\", right_on=\"datetime\", how=\"inner\")\n",
        "merged_data = merged_data.drop(columns=[\"RoundedDateTime\"])\n",
        "\n",
        "# Step 7: Filter required fields\n",
        "filtered_data = merged_data[[\"image_timestamp\", \"roi\", \"iou_score\", \"stage\"]].copy()"
      ],
      "metadata": {
        "id": "mtx0H5oHKM4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1A6RWaXgnUg"
      },
      "outputs": [],
      "source": [
        "# Step 8: Extract ROI1 and ROI2 from 'roi' string\n",
        "def split_roi(roi_str):\n",
        "    try:\n",
        "        values = list(map(int, roi_str.strip('{}').split(',')))\n",
        "        return pd.Series(values[:2], index=[\"ROI1\", \"ROI2\"])\n",
        "    except:\n",
        "        return pd.Series([None, None], index=[\"ROI1\", \"ROI2\"])\n",
        "\n",
        "roi_split = filtered_data[\"roi\"].apply(split_roi)\n",
        "final_data = pd.concat([filtered_data.drop(columns=[\"roi\"]), roi_split], axis=1)\n",
        "final_data = final_data[[\"image_timestamp\", \"ROI1\", \"ROI2\", \"iou_score\", \"stage\"]]\n",
        "final_data[\"stage\"] = final_data[\"stage\"] * 30.48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuK0qD_fgnUg"
      },
      "outputs": [],
      "source": [
        "# Display the updated DataFrame\n",
        "print(final_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5Q4ZSZfgnUh"
      },
      "outputs": [],
      "source": [
        "final_data = final_data.sort_values(\"image_timestamp\")\n",
        "# Plot with secondary y-axis for stage data\n",
        "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Primary y-axis for ROI1 and ROI2\n",
        "ax1.plot(final_data[\"image_timestamp\"], final_data[\"ROI1\"], label=\"ROI1 Pixels\", color='tab:blue')\n",
        "ax1.plot(final_data[\"image_timestamp\"], final_data[\"ROI2\"], label=\"ROI2 Pixels\", color='tab:green')\n",
        "ax1.set_xlabel(\"Image Timestamp\")\n",
        "ax1.set_ylabel(\"ROI Pixel Values\", color='black')\n",
        "ax1.tick_params(axis='y', labelcolor='black')\n",
        "ax1.legend(loc=\"upper left\")\n",
        "\n",
        "# Secondary y-axis for stage data\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(final_data[\"image_timestamp\"], final_data[\"stage\"], label=\"USGS Stage (cm)\", color='tab:red', linestyle='--')\n",
        "ax2.set_ylabel(\"Stage (cm)\", color='tab:red')\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "ax2.legend(loc=\"upper right\")\n",
        "\n",
        "# Final plot adjustments\n",
        "plt.title(\"Time Series of ROI Pixel Values and USGS Stage\")\n",
        "fig.autofmt_xdate()\n",
        "fig.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot IoU score distribution to assess threshold\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(final_data[\"iou_score\"], bins=30, edgecolor='black', color='skyblue')\n",
        "plt.title(\"Distribution of IoU Scores\")\n",
        "plt.xlabel(\"IoU Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NCo14MnfMGkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the data to keep only rows with IoU >= 0.7\n",
        "filtered_high_iou = final_data[final_data[\"iou_score\"] >= 0.7].copy()\n",
        "\n",
        "filtered_high_iou.head()"
      ],
      "metadata": {
        "id": "BpP_y7rAMY1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l2R5RpkgnUh"
      },
      "outputs": [],
      "source": [
        "# Filter the main high-IoU dataset to include only images captured between 07:00 and 20:00\n",
        "time_filtered_df = filtered_high_iou.copy()\n",
        "time_filtered_df[\"hour\"] = time_filtered_df[\"image_timestamp\"].dt.hour\n",
        "\n",
        "# Include only records between 7 AM and 8 PM (inclusive)\n",
        "time_filtered_df = time_filtered_df[(time_filtered_df[\"hour\"] >= 7) & (time_filtered_df[\"hour\"] <= 20)].copy()\n",
        "\n",
        "# Drop the 'hour' column now that filtering is done\n",
        "time_filtered_df.drop(columns=[\"hour\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_filtered_df"
      ],
      "metadata": {
        "id": "EdBJoBwBP9Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_filtered_df = time_filtered_df.sort_values(\"image_timestamp\")\n",
        "\n",
        "# Re-plot with stage on a secondary y-axis and ROI values on primary y-axis\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Primary y-axis for ROI1 and ROI2\n",
        "ax1.plot(time_filtered_df[\"image_timestamp\"], time_filtered_df[\"ROI1\"], label=\"ROI1 Pixels\", color='tab:blue', alpha=0.6)\n",
        "ax1.plot(time_filtered_df[\"image_timestamp\"], time_filtered_df[\"ROI2\"], label=\"ROI2 Pixels\", color='tab:green', alpha=0.6)\n",
        "ax1.set_xlabel(\"Image Timestamp\")\n",
        "ax1.set_ylabel(\"ROI Pixel Values\", color='black')\n",
        "ax1.tick_params(axis='y', labelcolor='black')\n",
        "ax1.legend(loc=\"upper left\")\n",
        "\n",
        "# Secondary y-axis for USGS stage\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(time_filtered_df[\"image_timestamp\"], time_filtered_df[\"stage\"], label=\"USGS Stage (cm)\", color='tab:red', linestyle='--', alpha=0.9)\n",
        "ax2.set_ylabel(\"Stage (cm)\", color='tab:red')\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "ax2.legend(loc=\"upper right\")\n",
        "\n",
        "plt.title(\"Time Series with Dual Axes: ROI Pixels vs USGS Stage (7AM–8PM, IoU ≥ 0.7)\")\n",
        "plt.grid(True)\n",
        "fig.autofmt_xdate()\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YHw5CoFYQWJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXArTKXUgnUh"
      },
      "outputs": [],
      "source": [
        "# Step 1: Remove rows where ROI1 or ROI2 <= 100 (likely invalid segmentations)\n",
        "cleaned_df = time_filtered_df[(time_filtered_df[\"ROI1\"] > 100) & (time_filtered_df[\"ROI2\"] > 100)].copy()\n",
        "\n",
        "# Step 2: Clip ROI1 and ROI2 at their 99th percentile\n",
        "roi1_clip = cleaned_df[\"ROI1\"].quantile(0.99)\n",
        "roi2_clip = cleaned_df[\"ROI2\"].quantile(0.99)\n",
        "\n",
        "cleaned_df[\"ROI1\"] = cleaned_df[\"ROI1\"].clip(upper=roi1_clip)\n",
        "cleaned_df[\"ROI2\"] = cleaned_df[\"ROI2\"].clip(upper=roi2_clip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAfJDzu5gnUh"
      },
      "outputs": [],
      "source": [
        "# Sort the cleaned DataFrame for plotting\n",
        "cleaned_df_sorted = cleaned_df.sort_values(\"image_timestamp\")\n",
        "\n",
        "# Plot time series with dual y-axes\n",
        "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Left y-axis for ROI1 and ROI2\n",
        "ax1.plot(cleaned_df_sorted[\"image_timestamp\"], cleaned_df_sorted[\"ROI1\"], label=\"ROI1 Pixels\", color='tab:blue', alpha=0.7)\n",
        "ax1.plot(cleaned_df_sorted[\"image_timestamp\"], cleaned_df_sorted[\"ROI2\"], label=\"ROI2 Pixels\", color='tab:green', alpha=0.7)\n",
        "ax1.set_xlabel(\"Image Timestamp\")\n",
        "ax1.set_ylabel(\"ROI Pixel Values\", color='black')\n",
        "ax1.tick_params(axis='y', labelcolor='black')\n",
        "ax1.legend(loc=\"upper left\")\n",
        "\n",
        "# Right y-axis for stage\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(cleaned_df_sorted[\"image_timestamp\"], cleaned_df_sorted[\"stage\"], label=\"USGS Stage (cm)\", color='tab:red', linestyle='--', alpha=0.9)\n",
        "ax2.set_ylabel(\"Stage (cm)\", color='tab:red')\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "ax2.legend(loc=\"upper right\")\n",
        "\n",
        "plt.title(\"Cleaned Time Series: ROI Pixels vs Stage (7AM–8PM, IoU ≥ 0.7, Outliers Removed)\")\n",
        "plt.grid(True)\n",
        "fig.autofmt_xdate()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AehZOp5xgnUh"
      },
      "outputs": [],
      "source": [
        "# Apply the cutoff date to remove unreliable early segmentation data\n",
        "final_df = cleaned_df[cleaned_df[\"image_timestamp\"] >= \"2024-08-01\"].copy()\n",
        "\n",
        "# Compute Pearson and Spearman correlations on the final dataset\n",
        "pearson_corr_final = final_df[[\"ROI1\", \"ROI2\", \"stage\"]].corr(method=\"pearson\")\n",
        "spearman_corr_final = final_df[[\"ROI1\", \"ROI2\", \"stage\"]].corr(method=\"spearman\")\n",
        "\n",
        "pearson_corr_final, spearman_corr_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj_Kxgd6gnUi"
      },
      "outputs": [],
      "source": [
        "# Function to apply IQR-based outlier removal\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# Apply IQR filtering to both ROI1 and ROI2\n",
        "iqr_filtered_df = final_df.copy()\n",
        "iqr_filtered_df = remove_outliers_iqr(iqr_filtered_df, \"ROI1\")\n",
        "iqr_filtered_df = remove_outliers_iqr(iqr_filtered_df, \"ROI2\")\n",
        "\n",
        "# Sort for plotting\n",
        "iqr_filtered_df_sorted = iqr_filtered_df.sort_values(\"image_timestamp\")\n",
        "\n",
        "# Plot the new time series after IQR filtering\n",
        "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# ROI1 and ROI2 on left y-axis\n",
        "ax1.plot(iqr_filtered_df_sorted[\"image_timestamp\"], iqr_filtered_df_sorted[\"ROI1\"], label=\"ROI1 Pixels\", color='tab:blue', alpha=0.7)\n",
        "ax1.plot(iqr_filtered_df_sorted[\"image_timestamp\"], iqr_filtered_df_sorted[\"ROI2\"], label=\"ROI2 Pixels\", color='tab:green', alpha=0.7)\n",
        "ax1.set_xlabel(\"Image Timestamp\", fontsize=14)\n",
        "ax1.set_ylabel(\"ROI Pixel Values\", color='black', fontsize=14)\n",
        "ax1.tick_params(axis='y', labelcolor='black', labelsize=12)\n",
        "ax1.tick_params(axis='x', labelsize=12)\n",
        "ax1.legend(loc=\"upper left\", fontsize=12)\n",
        "\n",
        "# Stage on right y-axis\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(iqr_filtered_df_sorted[\"image_timestamp\"], iqr_filtered_df_sorted[\"stage\"], label=\"USGS Stage (cm)\", color='tab:red', linestyle='--', alpha=0.9)\n",
        "ax2.set_ylabel(\"Stage (cm)\", color='tab:red', fontsize=14)\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=12)\n",
        "ax2.legend(loc=\"upper right\", fontsize=12)\n",
        "\n",
        "plt.title(\"Time Series After IQR-Based Outlier Removal (ROI1 & ROI2)\", fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"timeseries_stage.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iqr_filtered_df_sorted.to_csv(\"iqr_filtered_df_sorted.csv\", index=False)"
      ],
      "metadata": {
        "id": "vjoO2r9h5T7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iqr_filtered_df_sorted"
      ],
      "metadata": {
        "id": "-d9ekrETo_zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "affhvCuwgnUi"
      },
      "outputs": [],
      "source": [
        "# Compute Pearson and Spearman correlations on the IQR-filtered final dataset\n",
        "pearson_corr_iqr = iqr_filtered_df[[\"ROI1\", \"ROI2\", \"stage\"]].corr(method=\"pearson\")\n",
        "spearman_corr_iqr = iqr_filtered_df[[\"ROI1\", \"ROI2\", \"stage\"]].corr(method=\"spearman\")\n",
        "\n",
        "pearson_corr_iqr, spearman_corr_iqr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# Plot side-by-side heatmaps\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Pearson\n",
        "sns.heatmap(\n",
        "    pearson_corr_iqr,\n",
        "    annot=True,\n",
        "    cmap=\"coolwarm\",\n",
        "    vmin=-1, vmax=1,\n",
        "    ax=axes[0],\n",
        "    annot_kws={\"size\": 12},  # annotation font size\n",
        "    cbar_kws={\"shrink\": 0.8}\n",
        ")\n",
        "axes[0].set_title(\"Pearson Correlation\", fontsize=14)\n",
        "axes[0].tick_params(axis='both', labelsize=12)\n",
        "\n",
        "# Spearman\n",
        "sns.heatmap(\n",
        "    spearman_corr_iqr,\n",
        "    annot=True,\n",
        "    cmap=\"coolwarm\",\n",
        "    vmin=-1, vmax=1,\n",
        "    ax=axes[1],\n",
        "    annot_kws={\"size\": 12},\n",
        "    cbar_kws={\"shrink\": 0.8}\n",
        ")\n",
        "axes[1].set_title(\"Spearman Correlation\", fontsize=14)\n",
        "axes[1].tick_params(axis='both', labelsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"correlation_stage.png\", dpi=300, bbox_inches='tight')  # save as PNG\n",
        "# plt.savefig(\"correlation_heatmaps.pdf\")  # alternative for PDF\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "orRO17adV6Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpLQdVrqgnUi"
      },
      "outputs": [],
      "source": [
        "# Perform extended EDA on the final IQR-filtered dataset\n",
        "\n",
        "eda_summary_final = {\n",
        "    \"Total Entries\": len(iqr_filtered_df),\n",
        "    \"ROI1 Range\": (iqr_filtered_df[\"ROI1\"].min(), iqr_filtered_df[\"ROI1\"].max()),\n",
        "    \"ROI2 Range\": (iqr_filtered_df[\"ROI2\"].min(), iqr_filtered_df[\"ROI2\"].max()),\n",
        "    \"Stage Range\": (iqr_filtered_df[\"stage\"].min(), iqr_filtered_df[\"stage\"].max()),\n",
        "    \"Mean ROI1\": iqr_filtered_df[\"ROI1\"].mean(),\n",
        "    \"Mean ROI2\": iqr_filtered_df[\"ROI2\"].mean(),\n",
        "    \"Mean Stage\": iqr_filtered_df[\"stage\"].mean(),\n",
        "    \"STD ROI1\": iqr_filtered_df[\"ROI1\"].std(),\n",
        "    \"STD ROI2\": iqr_filtered_df[\"ROI2\"].std(),\n",
        "    \"STD Stage\": iqr_filtered_df[\"stage\"].std(),\n",
        "    \"Skewness ROI1\": iqr_filtered_df[\"ROI1\"].skew(),\n",
        "    \"Skewness ROI2\": iqr_filtered_df[\"ROI2\"].skew(),\n",
        "    \"Skewness Stage\": iqr_filtered_df[\"stage\"].skew(),\n",
        "    \"Kurtosis ROI1\": iqr_filtered_df[\"ROI1\"].kurtosis(),\n",
        "    \"Kurtosis ROI2\": iqr_filtered_df[\"ROI2\"].kurtosis(),\n",
        "    \"Kurtosis Stage\": iqr_filtered_df[\"stage\"].kurtosis()\n",
        "}\n",
        "\n",
        "# Print summary if desired\n",
        "for k, v in eda_summary_final.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "# Check pairwise scatterplot matrix\n",
        "# Pairplot with font scaling and transparency\n",
        "pairplot = sns.pairplot(\n",
        "    iqr_filtered_df[[\"ROI1\", \"ROI2\", \"stage\"]],\n",
        "    corner=True,\n",
        "    plot_kws={\"alpha\": 0.4, \"s\": 25},  # scatter dot size and transparency\n",
        "    height=2.5,\n",
        ")\n",
        "# Set title with larger font\n",
        "pairplot.fig.suptitle(\"Pairwise Feature Distributions and Relationships\", fontsize=14, y=1.03)\n",
        "\n",
        "# Update font size for all axes in the pairplot\n",
        "for ax in pairplot.axes.flat:\n",
        "    if ax is not None:\n",
        "        ax.tick_params(axis='both', labelsize=12)\n",
        "        ax.xaxis.label.set_size(13)\n",
        "        ax.yaxis.label.set_size(13)\n",
        "\n",
        "# Save figure\n",
        "pairplot.savefig(\"pairwise_distribution.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# === Step 1: Prepare features and target ===\n",
        "X = iqr_filtered_df[[\"ROI1\", \"ROI2\"]]\n",
        "y = iqr_filtered_df[\"stage\"]\n",
        "timestamps = iqr_filtered_df[\"image_timestamp\"]\n",
        "\n",
        "# === Step 2: Train-Test Split (80/20) ===\n",
        "X_train, X_test, y_train, y_test, ts_train, ts_test = train_test_split(\n",
        "    X, y, timestamps, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 3: Fit model on training data ===\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# === Step 4: Predict on train and test sets ===\n",
        "y_train_pred = lin_reg.predict(X_train)\n",
        "y_test_pred = lin_reg.predict(X_test)\n",
        "\n",
        "# === Step 5: Compute train-test metrics ===\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# === Step 6: 5-Fold Cross-Validation (on full data) ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# R²\n",
        "r2_scores = cross_val_score(lin_reg, X, y, cv=kf, scoring=\"r2\")\n",
        "\n",
        "# RMSE (neg MSE → RMSE)\n",
        "neg_mse_scores = cross_val_score(lin_reg, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
        "rmse_scores = np.sqrt(-neg_mse_scores)\n",
        "\n",
        "# === Step 7: Summarize results ===\n",
        "results = {\n",
        "    \"Train R²\": train_r2,\n",
        "    \"Test R²\": test_r2,\n",
        "    \"Train RMSE\": train_rmse,\n",
        "    \"Test RMSE\": test_rmse,\n",
        "    \"Train MAE\": train_mae,\n",
        "    \"Test MAE\": test_mae,\n",
        "    \"CV R² Mean\": np.mean(r2_scores),\n",
        "    \"CV R² Std\": np.std(r2_scores),\n",
        "    \"CV RMSE Mean\": np.mean(rmse_scores),\n",
        "    \"CV RMSE Std\": np.std(rmse_scores),\n",
        "}\n",
        "\n",
        "# === Step 8: Display nicely ===\n",
        "for k, v in results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "-pfa98LcErkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IFwr2FWgnUi"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# === Step 1: Polynomial Feature Expansion (Degree 2) ===\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "X_full_poly = poly.transform(X)  # for cross-validation\n",
        "\n",
        "# === Optional: View feature names ===\n",
        "# print(poly.get_feature_names_out([\"ROI1\", \"ROI2\"]))\n",
        "\n",
        "# === Step 2: Train Model ===\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_poly, y_train)\n",
        "\n",
        "# === Step 3: Predictions ===\n",
        "y_train_pred = model.predict(X_train_poly)\n",
        "y_test_pred = model.predict(X_test_poly)\n",
        "\n",
        "# === Step 4: Train-Test Metrics ===\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(model, X_full_poly, y, cv=kf, scoring=\"r2\")\n",
        "cv_neg_mse = cross_val_score(model, X_full_poly, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
        "cv_rmse = np.sqrt(-cv_neg_mse)\n",
        "\n",
        "# === Step 6: Combine Metrics ===\n",
        "metrics_poly = {\n",
        "    \"Train R²\": train_r2,\n",
        "    \"Test R²\": test_r2,\n",
        "    \"Train RMSE\": train_rmse,\n",
        "    \"Test RMSE\": test_rmse,\n",
        "    \"Train MAE\": train_mae,\n",
        "    \"Test MAE\": test_mae,\n",
        "    \"CV R² Mean\": np.mean(cv_r2),\n",
        "    \"CV R² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse),\n",
        "}\n",
        "\n",
        "# === Step 7: Print Results Nicely ===\n",
        "for k, v in metrics_poly.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwfbkUj_gnUi"
      },
      "outputs": [],
      "source": [
        "# Define global axis limits with margin\n",
        "buffer = 0.05 * (y.max() - y.min())\n",
        "min_val = min(y.min(), y_train_pred.min(), y_test_pred.min()) - buffer\n",
        "max_val = max(y.max(), y_train_pred.max(), y_test_pred.max()) + buffer\n",
        "\n",
        "# Fit regression lines manually\n",
        "train_slope, train_intercept = np.polyfit(y_train, y_train_pred, 1)\n",
        "test_slope, test_intercept = np.polyfit(y_test, y_test_pred, 1)\n",
        "x_line = np.linspace(min_val, max_val, 100)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Train set\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.6, color='dodgerblue', edgecolor='k', s=50, label='Predictions')\n",
        "plt.plot(x_line, x_line, 'r--', linewidth=1.5, label='1:1 Line')\n",
        "plt.plot(x_line, train_slope * x_line + train_intercept, 'b-', linewidth=2, label='Regression Line')\n",
        "plt.title(\"Train Set: Actual vs Predicted Stage\", fontsize=14)\n",
        "plt.xlabel(\"Actual Stage (cm)\", fontsize=12)\n",
        "plt.ylabel(\"Predicted Stage (cm)\", fontsize=12)\n",
        "plt.xlim(min_val, max_val)\n",
        "plt.ylim(min_val, max_val)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=11)\n",
        "plt.tick_params(labelsize=11)\n",
        "\n",
        "# Add regression equation as boxed text\n",
        "plt.text(\n",
        "    0.05, 0.95,\n",
        "    f\"$y = {train_slope:.2f}x + {train_intercept:.2f}$\",\n",
        "    transform=plt.gca().transAxes,\n",
        "    fontsize=11,\n",
        "    verticalalignment='top',\n",
        "    bbox=dict(facecolor='white', edgecolor='blue', boxstyle='round,pad=0.4')\n",
        ")\n",
        "\n",
        "# Test set\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.6, color='forestgreen', edgecolor='k', s=50, label='Predictions')\n",
        "plt.plot(x_line, x_line, 'r--', linewidth=1.5, label='1:1 Line')\n",
        "plt.plot(x_line, test_slope * x_line + test_intercept, 'g-', linewidth=2, label='Regression Line')\n",
        "plt.title(\"Test Set: Actual vs Predicted Stage\", fontsize=14)\n",
        "plt.xlabel(\"Actual Stage (cm)\", fontsize=12)\n",
        "plt.ylabel(\"Predicted Stage (cm)\", fontsize=12)\n",
        "plt.xlim(min_val, max_val)\n",
        "plt.ylim(min_val, max_val)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=11)\n",
        "plt.tick_params(labelsize=11)\n",
        "\n",
        "# Add regression equation as boxed text\n",
        "plt.text(\n",
        "    0.05, 0.95,\n",
        "    f\"$y = {test_slope:.2f}x + {test_intercept:.2f}$\",\n",
        "    transform=plt.gca().transAxes,\n",
        "    fontsize=11,\n",
        "    verticalalignment='top',\n",
        "    bbox=dict(facecolor='white', edgecolor='green', boxstyle='round,pad=0.4')\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"scatter_stage.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slope, intercept = np.polyfit(y_test, y_test_pred, 1)\n",
        "print(f\"Test slope: {slope:.3f}, intercept: {intercept:.3f}\")\n"
      ],
      "metadata": {
        "id": "a266aw5KIXro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij_-_0UOgnUj"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# === Step 3: Tuned Random Forest Regressor ===\n",
        "rf_tuned = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42\n",
        ")\n",
        "rf_tuned.fit(X_train, y_train)\n",
        "\n",
        "# === Step 4: Predictions ===\n",
        "y_train_pred = rf_tuned.predict(X_train)\n",
        "y_test_pred = rf_tuned.predict(X_test)\n",
        "\n",
        "# === Step 5: Evaluation ===\n",
        "metrics_rf = {\n",
        "    \"Train R²\": r2_score(y_train, y_train_pred),\n",
        "    \"Test R²\": r2_score(y_test, y_test_pred),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred),\n",
        "}\n",
        "\n",
        "# === Step 6: Optional Cross-Validation (on full set) ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(rf_tuned, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(rf_tuned, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "metrics_rf.update({\n",
        "    \"CV R² Mean\": np.mean(cv_r2),\n",
        "    \"CV R² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse),\n",
        "})\n",
        "\n",
        "# === Step 7: Display nicely ===\n",
        "for k, v in metrics_rf.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# === Step 1: Define XGBoost Regressor ===\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    objective='reg:squarederror',  # prevents warning for regression\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === Step 2: Train on Train Set ===\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# === Step 3: Predict ===\n",
        "y_train_pred_xgb = xgb_model.predict(X_train)\n",
        "y_test_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# === Step 4: Train-Test Evaluation ===\n",
        "xgb_metrics = {\n",
        "    \"Train R²\": r2_score(y_train, y_train_pred_xgb),\n",
        "    \"Test R²\": r2_score(y_test, y_test_pred_xgb),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred_xgb),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred_xgb),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred_xgb)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred_xgb)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred_xgb),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred_xgb)\n",
        "}\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(xgb_model, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(xgb_model, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "xgb_metrics.update({\n",
        "    \"CV R² Mean\": np.mean(cv_r2),\n",
        "    \"CV R² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse)\n",
        "})\n",
        "\n",
        "# === Step 6: Print Clean Summary ===\n",
        "for k, v in xgb_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "UQrxqxA3e4iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# === Step 1: Define LightGBM Regressor ===\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    num_leaves=31,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === Step 2: Train ===\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# === Step 3: Predict ===\n",
        "y_train_pred_lgb = lgb_model.predict(X_train)\n",
        "y_test_pred_lgb = lgb_model.predict(X_test)\n",
        "\n",
        "# === Step 4: Evaluate on Train and Test ===\n",
        "lgb_metrics = {\n",
        "    \"Train R²\": r2_score(y_train, y_train_pred_lgb),\n",
        "    \"Test R²\": r2_score(y_test, y_test_pred_lgb),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred_lgb),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred_lgb),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred_lgb)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred_lgb)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred_lgb),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred_lgb)\n",
        "}\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(lgb_model, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(lgb_model, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "lgb_metrics.update({\n",
        "    \"CV R² Mean\": np.mean(cv_r2),\n",
        "    \"CV R² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse)\n",
        "})\n",
        "\n",
        "# === Step 6: Print Results ===\n",
        "for k, v in lgb_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "n9DlN55Pe43Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "Gxb_GWMOch6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 2: Define SVR Pipeline ===\n",
        "svr_model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.01)\n",
        ")\n",
        "\n",
        "# === Step 3: Train and Predict ===\n",
        "svr_model.fit(X_train, y_train)\n",
        "y_train_pred_svr = svr_model.predict(X_train)\n",
        "y_test_pred_svr = svr_model.predict(X_test)\n",
        "\n",
        "# === Step 4: Evaluation Metrics ===\n",
        "svr_metrics = {\n",
        "    \"Train R²\": r2_score(y_train, y_train_pred_svr),\n",
        "    \"Test R²\": r2_score(y_test, y_test_pred_svr),\n",
        "    \"Train MAE\": mean_absolute_error(y_train, y_train_pred_svr),\n",
        "    \"Test MAE\": mean_absolute_error(y_test, y_test_pred_svr),\n",
        "    \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred_svr)),\n",
        "    \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred_svr)),\n",
        "    \"Train MSE\": mean_squared_error(y_train, y_train_pred_svr),\n",
        "    \"Test MSE\": mean_squared_error(y_test, y_test_pred_svr)\n",
        "}\n",
        "\n",
        "# === Step 5: Cross-Validation ===\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2 = cross_val_score(svr_model, X, y, cv=cv, scoring=\"r2\")\n",
        "cv_rmse = np.sqrt(-cross_val_score(svr_model, X, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
        "\n",
        "svr_metrics.update({\n",
        "    \"CV R² Mean\": np.mean(cv_r2),\n",
        "    \"CV R² Std\": np.std(cv_r2),\n",
        "    \"CV RMSE Mean\": np.mean(cv_rmse),\n",
        "    \"CV RMSE Std\": np.std(cv_rmse)\n",
        "})\n",
        "\n",
        "# === Step 6: Print Results ===\n",
        "for k, v in svr_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "j5OJSztnflPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "STtqjfowiOsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error"
      ],
      "metadata": {
        "id": "alDZMY2Z7_c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Prepare the data\n",
        "df_sorted = iqr_filtered_df.sort_values(\"image_timestamp\").reset_index(drop=True)\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "df_scaled = df_sorted.copy()\n",
        "df_scaled[[\"ROI1\", \"ROI2\"]] = scaler_X.fit_transform(df_sorted[[\"ROI1\", \"ROI2\"]])\n",
        "df_scaled[\"stage\"] = scaler_y.fit_transform(df_sorted[[\"stage\"]])\n"
      ],
      "metadata": {
        "id": "68NFeh2GgllN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Dataset Class\n",
        "class StageSequenceDataset(Dataset):\n",
        "    def __init__(self, df, seq_len=10):\n",
        "        self.seq_len = seq_len\n",
        "        self.features = df[[\"ROI1\", \"ROI2\"]].values.astype(np.float32)\n",
        "        self.targets = df[\"stage\"].values.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.features[idx:idx + self.seq_len]\n",
        "        y = self.targets[idx + self.seq_len]\n",
        "        return torch.tensor(X), torch.tensor(y)"
      ],
      "metadata": {
        "id": "y8sw0Ln_gKtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: LSTM Model\n",
        "class StageLSTM(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_size=128, num_layers=2, dropout=0.2):\n",
        "        super(StageLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out.squeeze()"
      ],
      "metadata": {
        "id": "uO7FByhdg4OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset\n",
        "seq_len = 10\n",
        "dataset = StageSequenceDataset(df_scaled, seq_len=seq_len)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * train_size)\n",
        "\n",
        "actual_train_ds = Subset(dataset, range(train_size - val_size))\n",
        "val_ds = Subset(dataset, range(train_size - val_size, train_size))\n",
        "test_ds = Subset(dataset, range(train_size, len(dataset)))\n",
        "\n",
        "train_loader = DataLoader(actual_train_ds, batch_size=32, shuffle=False)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize model\n",
        "model = StageLSTM()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "# Training loop with early stopping\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(X_batch)\n",
        "        loss = criterion(preds, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            preds = model(X_batch)\n",
        "            val_loss += criterion(preds, y_batch).item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping condition\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        best_model_state = model.state_dict()\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"⏹️ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)\n"
      ],
      "metadata": {
        "id": "cvVlhoLNhAvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test set\n",
        "model.eval()\n",
        "y_pred, y_true = [], []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        preds = model(X_batch)\n",
        "        y_pred.extend(preds.numpy())\n",
        "        y_true.extend(y_batch.numpy())\n",
        "\n",
        "# Inverse scaling\n",
        "y_pred_inv = scaler_y.inverse_transform(np.array(y_pred).reshape(-1, 1)).flatten()\n",
        "y_true_inv = scaler_y.inverse_transform(np.array(y_true).reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"LSTM with Early Stopping (Test)\")\n",
        "print(\"Test R²:\", r2_score(y_true_inv, y_pred_inv))\n",
        "print(\"Test MAE:\", mean_absolute_error(y_true_inv, y_pred_inv))\n",
        "\n",
        "# Evaluation on training set\n",
        "y_train_pred, y_train_true = [], []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in DataLoader(actual_train_ds, batch_size=32, shuffle=False):\n",
        "        preds = model(X_batch)\n",
        "        y_train_pred.extend(preds.numpy())\n",
        "        y_train_true.extend(y_batch.numpy())\n",
        "\n",
        "# Inverse scaling\n",
        "y_train_pred_inv = scaler_y.inverse_transform(np.array(y_train_pred).reshape(-1, 1)).flatten()\n",
        "y_train_true_inv = scaler_y.inverse_transform(np.array(y_train_true).reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"LSTM with Early Stopping (Train)\")\n",
        "print(\"Train R²:\", r2_score(y_train_true_inv, y_train_pred_inv))\n",
        "print(\"Train MAE:\", mean_absolute_error(y_train_true_inv, y_train_pred_inv))\n"
      ],
      "metadata": {
        "id": "rcg0OuRbqgei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_MErpK4iMvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Step 1: Combine all model metrics into a dictionary ===\n",
        "model_results = {\n",
        "    \"SVR\": svr_metrics,\n",
        "    \"Random Forest\": metrics_rf,\n",
        "    \"XGBoost\": xgb_metrics,\n",
        "    \"LightGBM\": lgb_metrics,\n",
        "    \"Polynomial Regression (d=2)\": metrics_poly,\n",
        "    \"Linear Regression\": results\n",
        "}\n",
        "\n",
        "# === Step 2: Create DataFrame ===\n",
        "ranking_df = pd.DataFrame(model_results).T[[\n",
        "    \"Test R²\", \"Test MAE\", \"Test RMSE\", \"CV R² Mean\", \"CV RMSE Mean\"\n",
        "]]\n",
        "ranking_df.columns = [\"R²\", \"MAE\", \"RMSE\", \"CV_R²\", \"CV_RMSE\"]\n",
        "\n",
        "# === Step 3: Rank models (lower rank is better) ===\n",
        "ranking_df[\"R²_rank\"] = ranking_df[\"R²\"].rank(ascending=False)\n",
        "ranking_df[\"MAE_rank\"] = ranking_df[\"MAE\"].rank(ascending=True)\n",
        "ranking_df[\"RMSE_rank\"] = ranking_df[\"RMSE\"].rank(ascending=True)\n",
        "ranking_df[\"CV_R²_rank\"] = ranking_df[\"CV_R²\"].rank(ascending=False)\n",
        "ranking_df[\"CV_RMSE_rank\"] = ranking_df[\"CV_RMSE\"].rank(ascending=True)\n",
        "\n",
        "# === Step 4: Calculate average rank and sort ===\n",
        "ranking_df[\"Avg_Rank\"] = ranking_df[\n",
        "    [\"R²_rank\", \"MAE_rank\", \"RMSE_rank\", \"CV_R²_rank\", \"CV_RMSE_rank\"]\n",
        "].mean(axis=1)\n",
        "\n",
        "ranking_df = ranking_df.sort_values(\"Avg_Rank\")\n",
        "\n",
        "# Display or save\n",
        "print(ranking_df[[\"R²\", \"MAE\", \"RMSE\", \"CV_R²\", \"CV_RMSE\", \"Avg_Rank\"]])\n",
        "# ranking_df.to_csv(\"model_ranking.csv\", index=True)"
      ],
      "metadata": {
        "id": "ONS_mDKLZkZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Predictions from the top 3 models ===\n",
        "# Replace these with your actual prediction variables\n",
        "pred_svr = y_test_pred_svr      # SVR prediction\n",
        "pred_rf = y_test_pred           # RF prediction\n",
        "pred_xgb = y_test_pred_xgb      # XGBoost prediction\n",
        "\n",
        "# === STEP 2: Create stacked combinations ===\n",
        "stack_svr_rf   = np.vstack([pred_svr, pred_rf]).T\n",
        "stack_svr_xgb  = np.vstack([pred_svr, pred_xgb]).T\n",
        "stack_rf_xgb   = np.vstack([pred_rf, pred_xgb]).T\n",
        "stack_all_3    = np.vstack([pred_svr, pred_rf, pred_xgb]).T\n",
        "\n",
        "# === STEP 3: Meta-model (stacked ensemble) predictions ===\n",
        "stacked_svr_rf   = LinearRegression().fit(stack_svr_rf, y_test).predict(stack_svr_rf)\n",
        "stacked_svr_xgb  = LinearRegression().fit(stack_svr_xgb, y_test).predict(stack_svr_xgb)\n",
        "stacked_rf_xgb   = LinearRegression().fit(stack_rf_xgb, y_test).predict(stack_rf_xgb)\n",
        "stacked_all_3    = LinearRegression().fit(stack_all_3, y_test).predict(stack_all_3)\n",
        "\n",
        "# === STEP 4: Simple averages ===\n",
        "avg_svr_rf   = np.mean(stack_svr_rf, axis=1)\n",
        "avg_svr_xgb  = np.mean(stack_svr_xgb, axis=1)\n",
        "avg_rf_xgb   = np.mean(stack_rf_xgb, axis=1)\n",
        "avg_all_3    = np.mean(stack_all_3, axis=1)\n",
        "\n",
        "# === STEP 5: Weighted average (customizable weights) ===\n",
        "weighted_avg = 0.4 * pred_rf + 0.4 * pred_svr + 0.2 * pred_xgb\n",
        "\n",
        "# === STEP 6: Evaluation function ===\n",
        "def evaluate(y_true, y_pred):\n",
        "    return {\n",
        "        \"R²\": r2_score(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    }\n",
        "\n",
        "# === STEP 7: Compute metrics for all ensemble strategies ===\n",
        "ensemble_results = {\n",
        "    \"Simple Avg (SVR + RF)\": evaluate(y_test, avg_svr_rf),\n",
        "    \"Simple Avg (SVR + XGB)\": evaluate(y_test, avg_svr_xgb),\n",
        "    \"Simple Avg (RF + XGB)\": evaluate(y_test, avg_rf_xgb),\n",
        "    \"Simple Avg (All 3)\": evaluate(y_test, avg_all_3),\n",
        "    \"Weighted Avg (0.4 RF + 0.4 SVR + 0.2 XGB)\": evaluate(y_test, weighted_avg),\n",
        "    \"Stacked (SVR + RF)\": evaluate(y_test, stacked_svr_rf),\n",
        "    \"Stacked (SVR + XGB)\": evaluate(y_test, stacked_svr_xgb),\n",
        "    \"Stacked (RF + XGB)\": evaluate(y_test, stacked_rf_xgb),\n",
        "    \"Stacked (All 3)\": evaluate(y_test, stacked_all_3)\n",
        "}\n",
        "\n",
        "# === STEP 8: Convert to DataFrame and sort ===\n",
        "ensemble_df = pd.DataFrame(ensemble_results).T\n",
        "ensemble_df = ensemble_df.sort_values(\"R²\", ascending=False)\n",
        "\n",
        "# Display the final table\n",
        "print(ensemble_df)\n",
        "# Optional: Save to CSV\n",
        "# ensemble_df.to_csv(\"ensemble_comparison_top3.csv\", index=True)"
      ],
      "metadata": {
        "id": "Hx0uX4D8FP-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === BASE MODELS ===\n",
        "base_models = {\n",
        "    \"SVR\": svr_model,\n",
        "    \"Random Forest\": rf_tuned,\n",
        "    \"XGBoost\": xgb_model\n",
        "}\n",
        "\n",
        "# === PREPARE OOF PREDICTIONS ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "oof_preds = {name: np.zeros_like(y_train) for name in base_models}\n",
        "test_preds = {name: [] for name in base_models}\n",
        "\n",
        "# === 1. Generate OOF for training and test predictions ===\n",
        "for train_idx, val_idx in kf.split(X_train):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    for name, model in base_models.items():\n",
        "        model.fit(X_tr, y_tr)\n",
        "        oof_preds[name][val_idx] = model.predict(X_val)\n",
        "        test_preds[name].append(model.predict(X_test))  # accumulate fold predictions\n",
        "\n",
        "# === 2. Stack into new training and test matrices ===\n",
        "X_meta_train = np.vstack([oof_preds[name] for name in base_models]).T\n",
        "X_meta_test = np.mean([np.vstack(test_preds[name]) for name in base_models], axis=1).T\n",
        "\n",
        "# === 3. Train meta-model on OOF predictions ===\n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(X_meta_train, y_train)\n",
        "\n",
        "# === 4. Predict on holdout test set ===\n",
        "meta_pred_test = meta_model.predict(X_meta_test)\n",
        "\n",
        "# === 5. Evaluate final stacked model ===\n",
        "def evaluate(y_true, y_pred):\n",
        "    return {\n",
        "        \"R²\": r2_score(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    }\n",
        "\n",
        "stacked_cv_results = evaluate(y_test, meta_pred_test)\n",
        "print(\"Cross-Validated Stacked Ensemble Performance:\")\n",
        "for k, v in stacked_cv_results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "unCXNAYAdRkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Set global font to bold ===\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.rcParams['legend.fontsize'] = 14\n",
        "\n",
        "# === Prepare plot data ===\n",
        "df_plot = pd.DataFrame({\n",
        "    \"timestamp\": ts_test,\n",
        "    \"True Stage\": y_test,\n",
        "    \"Simple Avg (SVR + RF)\": avg_svr_rf,\n",
        "    \"Weighted Avg (0.4 RF + 0.4 SVR + 0.2 XGB)\": weighted_avg,\n",
        "    \"Stacked Ensemble (All 3)\": stacked_all_3\n",
        "}).sort_values(\"timestamp\")\n",
        "\n",
        "# === Create subplots ===\n",
        "fig, axs = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
        "\n",
        "# Plot 1: Simple Average\n",
        "axs[0].plot(df_plot[\"timestamp\"], df_plot[\"True Stage\"], label=\"True Stage\", color=\"black\", linewidth=2)\n",
        "axs[0].plot(df_plot[\"timestamp\"], df_plot[\"Simple Avg (SVR + RF)\"], label=\"Simple Avg (SVR + RF)\", color=\"royalblue\", linewidth=2)\n",
        "axs[0].set_title(\"Simple Average (SVR + RF) vs. True Stage\")\n",
        "axs[0].set_ylabel(\"Stage (cm)\", fontsize=14)\n",
        "axs[0].legend()\n",
        "axs[0].tick_params(axis='both', labelsize=14)\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot 2: Weighted Average\n",
        "axs[1].plot(df_plot[\"timestamp\"], df_plot[\"True Stage\"], label=\"True Stage\", color=\"black\", linewidth=2)\n",
        "axs[1].plot(df_plot[\"timestamp\"], df_plot[\"Weighted Avg (0.4 RF + 0.4 SVR + 0.2 XGB)\"], label=\"Weighted Avg\", color=\"darkorange\", linewidth=2)\n",
        "axs[1].set_title(\"Weighted Average vs. True Stage\")\n",
        "axs[1].set_ylabel(\"Stage (cm)\", fontsize=14)\n",
        "axs[1].legend()\n",
        "axs[1].tick_params(axis='both', labelsize=14)\n",
        "axs[1].grid(True)\n",
        "\n",
        "# Plot 3: Stacked Ensemble\n",
        "axs[2].plot(df_plot[\"timestamp\"], df_plot[\"True Stage\"], label=\"True Stage\", color=\"black\", linewidth=2)\n",
        "axs[2].plot(df_plot[\"timestamp\"], df_plot[\"Stacked Ensemble (All 3)\"], label=\"Stacked Ensemble (All 3)\", color=\"seagreen\", linewidth=2)\n",
        "axs[2].set_title(\"Stacked Ensemble (All 3) vs. True Stage\")\n",
        "axs[2].set_xlabel(\"Timestamp\", fontsize=14)\n",
        "axs[2].set_ylabel(\"Stage (cm)\", fontsize=14)\n",
        "axs[2].legend()\n",
        "axs[2].tick_params(labelsize=14)\n",
        "axs[2].tick_params(axis='both', labelsize=14)\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# === Save figure if needed ===\n",
        "plt.savefig(\"stacked_stage.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HyIdnICDtQrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# Titles and predictions\n",
        "titles = [\"Simple Avg (SVR + RF)\", \"Weighted Avg\", \"Stacked Ensemble (All 3)\"]\n",
        "predictions = [avg_svr_rf, weighted_avg, stacked_all_3]\n",
        "\n",
        "# Plot each ensemble prediction vs. actual stage\n",
        "for ax, name, pred in zip(axs, titles, predictions):\n",
        "    # Scatter plot\n",
        "    ax.scatter(y_test, pred, alpha=0.7, edgecolors='k')\n",
        "\n",
        "    # 1:1 reference line\n",
        "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"1:1 Line\")\n",
        "\n",
        "    # Regression line\n",
        "    coeffs = np.polyfit(y_test, pred, deg=1)\n",
        "    reg_line = np.poly1d(coeffs)\n",
        "    ax.plot(y_test, reg_line(y_test), color='blue', linewidth=2, label=\"Regression Line\")\n",
        "\n",
        "    # Labels and formatting\n",
        "    ax.set_xlabel(\"Actual Stage (cm)\", fontsize=14)\n",
        "    ax.set_title(name, fontsize=15)\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "    ax.legend()\n",
        "\n",
        "# Shared Y-axis label\n",
        "axs[0].set_ylabel(\"Predicted Stage (cm)\", fontsize=14)\n",
        "\n",
        "# Main title\n",
        "fig.suptitle(\"Actual vs Predicted Stage (Ensemble Models)\", fontsize=16)\n",
        "\n",
        "# Layout adjustment and save\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.savefig(\"ensemble_scatter.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tp4s6BIWrPM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Calculate Residuals ===\n",
        "resid_simple = y_test - avg_svr_rf\n",
        "resid_weighted = y_test - weighted_avg\n",
        "resid_stacked = y_test - stacked_all_3\n",
        "\n",
        "# === Create subplots ===\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# Titles and predictions\n",
        "titles = [\"Simple Avg (SVR + RF)\", \"Weighted Avg\", \"Stacked Ensemble (All 3)\"]\n",
        "predictions = [avg_svr_rf, weighted_avg, stacked_all_3]\n",
        "residuals = [resid_simple, resid_weighted, resid_stacked]\n",
        "\n",
        "# Plot residuals\n",
        "for ax, name, pred, resid in zip(axs, titles, predictions, residuals):\n",
        "    ax.scatter(pred, resid, alpha=0.7, edgecolors='k')\n",
        "    ax.axhline(0, color='red', linestyle='--')\n",
        "    ax.set_xlabel(\"Predicted Stage (cm)\", fontsize=14)\n",
        "    ax.set_title(f\"{name}\\n$R^2$ = {r2_score(y_test, pred):.3f}, MAE = {mean_absolute_error(y_test, pred):.4f}\", fontsize=13)\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "\n",
        "# Shared Y-axis label\n",
        "axs[0].set_ylabel(\"Residual (Actual - Predicted) (cm)\", fontsize=14)\n",
        "\n",
        "# Layout and save\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"ensemble_residuals.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m4CIlo-fjk5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Calculate Prediction Errors ===\n",
        "error_simple = avg_svr_rf - y_test\n",
        "error_weighted = weighted_avg - y_test\n",
        "error_stacked = stacked_all_3 - y_test\n",
        "\n",
        "# === Create histograms of prediction errors ===\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# Titles and errors\n",
        "titles = [\"Simple Avg (SVR + RF)\", \"Weighted Avg\", \"Stacked Ensemble (All 3)\"]\n",
        "errors = [error_simple, error_weighted, error_stacked]\n",
        "\n",
        "for ax, name, error in zip(axs, titles, errors):\n",
        "    ax.hist(error, bins=40, color='skyblue', edgecolor='black')\n",
        "    ax.axvline(0, color='red', linestyle='--')\n",
        "    ax.set_title(f\"{name} Error Histogram\", fontsize=14)\n",
        "    ax.set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "    ax.tick_params(axis='both', labelsize=14)\n",
        "\n",
        "# Shared Y-axis label\n",
        "axs[0].set_ylabel(\"Frequency\", fontsize=14)\n",
        "\n",
        "# Layout and optional save\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"ensemble_error.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o4o1g5k3jnBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_stage = y_test.values\n",
        "pred_simple = avg_svr_rf\n",
        "pred_weighted = weighted_avg\n",
        "pred_stacked = stacked_all_3\n",
        "\n",
        "# Summary metrics\n",
        "summary_metrics = pd.DataFrame({\n",
        "    \"Model\": [\"Simple Avg (2 models)\", \"Weighted Avg\", \"Stacked Ensemble (3 models)\"],\n",
        "    \"R²\": [\n",
        "        r2_score(true_stage, pred_simple),\n",
        "        r2_score(true_stage, pred_weighted),\n",
        "        r2_score(true_stage, pred_stacked)\n",
        "    ],\n",
        "    \"MAE\": [\n",
        "        mean_absolute_error(true_stage, pred_simple),\n",
        "        mean_absolute_error(true_stage, pred_weighted),\n",
        "        mean_absolute_error(true_stage, pred_stacked)\n",
        "    ]\n",
        "})\n",
        "\n",
        "summary_metrics"
      ],
      "metadata": {
        "id": "LnYtuL7HPcR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": [\"ROI1\", \"ROI2\"],\n",
        "    \"Importance\": [0.42, 0.58]\n",
        "})\n",
        "\n",
        "# Bar chart for feature importance\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.barh(feature_importance_df[\"Feature\"], feature_importance_df[\"Importance\"], color='skyblue')\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.title(\"Feature Importance (e.g., from Stacked Meta-Model)\")\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KsbZj-8bPwXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bland-Altman plot function\n",
        "def bland_altman_plot(actual, predicted, model_name):\n",
        "    mean_values = (actual + predicted) / 2\n",
        "    diff = actual - predicted\n",
        "    mean_diff = np.mean(diff)\n",
        "    std_diff = np.std(diff)\n",
        "    upper_limit = mean_diff + 1.96 * std_diff\n",
        "    lower_limit = mean_diff - 1.96 * std_diff\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.scatter(mean_values, diff, alpha=0.6, edgecolors='k', color='cornflowerblue')\n",
        "    plt.axhline(mean_diff, color='red', linestyle='--', label=f'Mean Diff: {mean_diff:.3f}')\n",
        "    plt.axhline(upper_limit, color='grey', linestyle='--', label=f'+1.96 SD: {upper_limit:.3f}')\n",
        "    plt.axhline(lower_limit, color='grey', linestyle='--', label=f'-1.96 SD: {lower_limit:.3f}')\n",
        "    plt.fill_between(mean_values, lower_limit, upper_limit, color='grey', alpha=0.1)\n",
        "\n",
        "    plt.title(f'Bland-Altman Plot ({model_name})', fontsize=14)\n",
        "    plt.xlabel('Mean of Actual and Predicted Stage (cm)', fontsize=14)\n",
        "    plt.ylabel('Residual (Actual - Predicted) (cm)', fontsize=14)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True)\n",
        "    plt.tick_params(axis='both', labelsize=14)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig(f\"bland_altman_{model_name.lower().replace(' ', '_')}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Run for all three models\n",
        "for model_name, y_pred in zip(\n",
        "    [\"Simple Avg (SVR + RF)\", \"Weighted Avg\", \"Stacked Ensemble (All 3)\"],\n",
        "    [avg_svr_rf, weighted_avg, stacked_all_3]\n",
        "):\n",
        "    bland_altman_plot(y_test, y_pred, model_name)"
      ],
      "metadata": {
        "id": "IjzHh4maP2_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare residuals\n",
        "residuals = {\n",
        "    \"Simple Avg\": true_stage - pred_simple,\n",
        "    \"Weighted Avg\": true_stage - pred_weighted,\n",
        "    \"Stacked Ensemble\": true_stage - pred_stacked\n",
        "}"
      ],
      "metadata": {
        "id": "I2NQuDNZQFZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Function to plot residuals over time ===\n",
        "def plot_residuals_over_time(residuals_dict, timestamps):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    for label, resids in residuals_dict.items():\n",
        "        plt.plot(timestamps, resids, label=label, alpha=0.7)\n",
        "\n",
        "    plt.axhline(0, color='red', linestyle='--')\n",
        "    plt.title(\"Residuals Over Time\", fontsize=15)\n",
        "    plt.xlabel(\"Timestamp\", fontsize=13)\n",
        "    plt.ylabel(\"Residual (Actual - Predicted) (cm)\", fontsize=14)\n",
        "    plt.legend(fontsize=11, loc=\"lower left\")\n",
        "    plt.grid(True)\n",
        "    plt.tick_params(axis='both', labelsize=14)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig(\"ensemble_timeseries_residuals.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# === Ensure timestamps are aligned with y_test ===\n",
        "#timestamps_sorted = iqr_filtered_df.sort_values(\"image_timestamp\").iloc[-len(y_test):][\"image_timestamp\"]\n",
        "timestamps_sorted = iqr_filtered_df.loc[y_test.index, \"image_timestamp\"].sort_values()\n",
        "\n",
        "# === Residuals dictionary structure ===\n",
        "residuals = {\n",
        "    \"Simple Avg (SVR + RF)\": avg_svr_rf - y_test,\n",
        "    \"Weighted Avg\": weighted_avg - y_test,\n",
        "    \"Stacked Ensemble (All 3)\": stacked_all_3 - y_test\n",
        "}\n",
        "\n",
        "# === Plot ===\n",
        "plot_residuals_over_time(residuals_dict=residuals, timestamps=timestamps_sorted)\n"
      ],
      "metadata": {
        "id": "zF-ug-F4QCx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Compute residuals ===\n",
        "residual_simple = y_test - avg_svr_rf\n",
        "residual_weighted = y_test - weighted_avg\n",
        "residual_stacked = y_test - stacked_all_3\n",
        "\n",
        "# === Create subplots ===\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# === Simple Avg plot ===\n",
        "sns.kdeplot(\n",
        "    residual_simple, ax=axes[0], fill=True,\n",
        "    color=\"#1f77b4\", alpha=0.5, linewidth=1\n",
        ")\n",
        "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=1.2)\n",
        "axes[0].set_title(\"Simple Avg (SVR + RF)\", fontsize=14)\n",
        "axes[0].set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "axes[0].set_ylabel(\"Density\", fontsize=14)\n",
        "axes[0].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "# === Weighted Avg plot ===\n",
        "sns.kdeplot(\n",
        "    residual_weighted, ax=axes[1], fill=True,\n",
        "    color=\"#ff7f0e\", alpha=0.4, linewidth=1\n",
        ")\n",
        "axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1.2)\n",
        "axes[1].set_title(\"Weighted Avg\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "axes[1].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "# === Stacked Ensemble plot ===\n",
        "sns.kdeplot(\n",
        "    residual_stacked, ax=axes[2], fill=True,\n",
        "    color=\"#2ca02c\", alpha=0.3, linewidth=1\n",
        ")\n",
        "axes[2].axvline(x=0, color='black', linestyle='--', linewidth=1.2)\n",
        "axes[2].set_title(\"Stacked Ensemble (All 3)\", fontsize=14)\n",
        "axes[2].set_xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "axes[2].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "# === Final layout ===\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"ensemble_error_pred_separate.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p1MaKKJtZf_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# === Compute residuals ===\n",
        "residual_simple = y_test - avg_svr_rf\n",
        "residual_weighted = y_test - weighted_avg\n",
        "residual_stacked = y_test - stacked_all_3\n",
        "\n",
        "# === Create KDE plot ===\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "sns.kdeplot(\n",
        "    residual_simple, label=\"Simple Avg (SVR + RF)\", fill=True,\n",
        "    color=\"#1f77b4\", alpha=0.5, linewidth=1\n",
        ")\n",
        "sns.kdeplot(\n",
        "    residual_weighted, label=\"Weighted Avg\", fill=True,\n",
        "    color=\"#ff7f0e\", alpha=0.4, linewidth=1\n",
        ")\n",
        "sns.kdeplot(\n",
        "    residual_stacked, label=\"Stacked Ensemble (All 3)\", fill=True,\n",
        "    color=\"#2ca02c\", alpha=0.3, linewidth=1\n",
        ")\n",
        "\n",
        "# Reference line at zero\n",
        "plt.axvline(x=0, color='black', linestyle='--', linewidth=1.2)\n",
        "\n",
        "# === Labels and title ===\n",
        "plt.title(\"Prediction Error Distribution (Ensemble Models)\", fontsize=14)\n",
        "plt.xlabel(\"Prediction Error (cm)\", fontsize=14)\n",
        "plt.ylabel(\"Density\", fontsize=14)\n",
        "plt.legend(fontsize=14)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "plt.tick_params(axis='both', labelsize=14)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "plt.savefig(\"ensemble_error_pred.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WjPPdkEUSQrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Create a summary dataframe\n",
        "summary_stats = pd.DataFrame({\n",
        "    \"Model\": [\"Simple Avg (2)\", \"Weighted Avg\", \"Stacked Ensemble (3)\"],\n",
        "    \"Mean Error\": [residual_simple.mean(), residual_weighted.mean(), residual_stacked.mean()],\n",
        "    \"Std Dev\": [residual_simple.std(), residual_weighted.std(), residual_stacked.std()],\n",
        "    \"Skewness\": [skew(residual_simple), skew(residual_weighted), skew(residual_stacked)],\n",
        "    \"Kurtosis\": [kurtosis(residual_simple), kurtosis(residual_weighted), kurtosis(residual_stacked)]\n",
        "})\n",
        "\n",
        "summary_stats"
      ],
      "metadata": {
        "id": "8eIfWY0SS4I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_prediction_band(timestamps, y_true, y_pred, model_name=\"Model\", color=\"blue\", band_cm=5):\n",
        "    \"\"\"\n",
        "    Plot prediction with ±5 cm band\n",
        "    \"\"\"\n",
        "    #band_ft = band_cm / 30.48  # Convert cm to feet\n",
        "    band_ft = band_cm\n",
        "    upper = y_pred + band_ft\n",
        "    lower = y_pred - band_ft\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(timestamps, y_true, label=\"True Stage\", color=\"black\", linewidth=2)\n",
        "    plt.plot(timestamps, y_pred, label=f\"Predicted ({model_name})\", color=color, linewidth=1.5)\n",
        "    plt.fill_between(timestamps, lower, upper, color=color, alpha=0.2, label=f\"±{band_cm} cm Interval\")\n",
        "    plt.title(f\"{model_name} Prediction with ±{band_cm} cm Band\")\n",
        "    plt.xlabel(\"Datetime\")\n",
        "    plt.ylabel(\"Stage (cm)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "V_Z_O4RYm1YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct test set with timestamps\n",
        "X_test_with_time = X_test.copy()\n",
        "X_test_with_time[\"timestamp\"] = iqr_filtered_df.loc[X_test.index, \"image_timestamp\"]\n",
        "X_test_with_time[\"true_stage\"] = y_test.values\n",
        "X_test_with_time[\"simple_avg\"] = avg_svr_rf\n",
        "X_test_with_time[\"weighted_avg\"] = weighted_avg\n",
        "X_test_with_time[\"stacked_ensemble\"] = stacked_all_3\n",
        "\n",
        "# Sort by timestamp\n",
        "X_test_sorted = X_test_with_time.sort_values(\"timestamp\")\n",
        "timestamps_sorted = X_test_sorted[\"timestamp\"]\n",
        "y_test_true_sorted = X_test_sorted[\"true_stage\"]\n",
        "y_pred_simple_sorted = X_test_sorted[\"simple_avg\"]\n",
        "y_pred_weighted_sorted = X_test_sorted[\"weighted_avg\"]\n",
        "y_pred_stacked_sorted = X_test_sorted[\"stacked_ensemble\"]\n"
      ],
      "metadata": {
        "id": "oqyyHFipoEN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_band(timestamps_sorted, y_test_true_sorted, y_pred_simple_sorted, model_name=\"Simple Avg (2 models)\", color=\"blue\")\n",
        "plot_prediction_band(timestamps_sorted, y_test_true_sorted, y_pred_weighted_sorted, model_name=\"Weighted Avg\", color=\"orange\")\n",
        "plot_prediction_band(timestamps_sorted, y_test_true_sorted, y_pred_stacked_sorted, model_name=\"Stacked Ensemble (3 models)\", color=\"green\")\n"
      ],
      "metadata": {
        "id": "jjbdZ5bgWLiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage Model Prediction"
      ],
      "metadata": {
        "id": "k-meFgCrZBg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(svr_model, \"svr_model.pkl\")\n",
        "joblib.dump(rf_tuned, \"rf_model.pkl\")\n",
        "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
        "meta_model_3 = LinearRegression().fit(stack_all_3, y_test)\n",
        "joblib.dump(meta_model_3, \"stacked_meta_model.pkl\")\n"
      ],
      "metadata": {
        "id": "Kub6AZX0XHo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load all models\n",
        "svr_model = joblib.load(\"svr_model.pkl\")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "xgb_model = joblib.load(\"xgb_model.pkl\")\n",
        "meta_model_3 = joblib.load(\"stacked_meta_model.pkl\")\n",
        "\n",
        "def predict_stage_from_segmentation(roi1, roi2):\n",
        "    \"\"\"\n",
        "    Predict water stage from ROI1 and ROI2 (segmentation output)\n",
        "    using stacked ensemble model.\n",
        "    \"\"\"\n",
        "    features = np.array([[roi1, roi2]])\n",
        "\n",
        "    # Base model predictions\n",
        "    pred_svr = svr_model.predict(features)[0]\n",
        "    pred_rf = rf_model.predict(features)[0]\n",
        "    pred_xgb = xgb_model.predict(features)[0]\n",
        "\n",
        "    # Stack and predict stage\n",
        "    stacked_input = np.array([[pred_svr, pred_rf, pred_xgb]])\n",
        "    stage_prediction = meta_model_3.predict(stacked_input)[0]\n",
        "\n",
        "    return stage_prediction\n"
      ],
      "metadata": {
        "id": "WslAqqgjZAQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose your segmentation gives ROI1=0.62, ROI2=0.45\n",
        "roi1 = 0.62\n",
        "roi2 = 0.45\n",
        "\n",
        "predicted_stage = predict_stage_from_segmentation(roi1, roi2)\n",
        "print(f\"Predicted Stage: {predicted_stage:.3f} ft\")\n"
      ],
      "metadata": {
        "id": "mD58e8nJZHld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = iqr_filtered_df[[\"ROI1\", \"ROI2\"]].copy()\n",
        "timestamps_all = iqr_filtered_df[\"image_timestamp\"]\n",
        "\n",
        "# Predict with base models\n",
        "y_pred_svr_all = svr_model.predict(X_all)\n",
        "y_pred_rf_all = rf_tuned.predict(X_all)\n",
        "y_pred_xgb_all = xgb_model.predict(X_all)\n",
        "\n",
        "# Stack predictions\n",
        "stacked_input_all = np.vstack([y_pred_svr_all, y_pred_rf_all, y_pred_xgb_all]).T\n",
        "\n",
        "# Predict stage using stacked ensemble model\n",
        "stage_pred_all = meta_model_3.predict(stacked_input_all)\n",
        "\n",
        "# Create output DataFrame\n",
        "predicted_stage_df = pd.DataFrame({\n",
        "    \"timestamp\": timestamps_all.values,\n",
        "    \"ROI1\": X_all[\"ROI1\"].values,\n",
        "    \"ROI2\": X_all[\"ROI2\"].values,\n",
        "    \"predicted_stage\": stage_pred_all\n",
        "})\n",
        "\n",
        "predicted_stage_df"
      ],
      "metadata": {
        "id": "3VBD8jEgmf6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discharge"
      ],
      "metadata": {
        "id": "L5EwylFBmg82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import curve_fit\n",
        "import pandas as pd\n",
        "\n",
        "usgs_discharge_df = pd.read_csv(\"/content/USGS_Discharge_FD.csv\", skiprows=1, header=None)\n",
        "\n",
        "# Rename the needed columns based on previous structure\n",
        "usgs_discharge_df = usgs_discharge_df.rename(columns={2: \"datetime\", 4: \"discharge\"})\n",
        "usgs_discharge_df[\"datetime\"] = pd.to_datetime(usgs_discharge_df[\"datetime\"], errors=\"coerce\")\n",
        "usgs_discharge_df[\"discharge\"] = pd.to_numeric(usgs_discharge_df[\"discharge\"], errors=\"coerce\")\n",
        "usgs_discharge_df = usgs_discharge_df.dropna(subset=[\"datetime\", \"discharge\"])\n",
        "usgs_discharge_df[\"discharge\"] *= 0.0283168\n",
        "# Filter discharge data to only timestamps that exist in iqr_filtered_df_sorted\n",
        "iqr_filtered_df_sorted[\"image_timestamp\"] = pd.to_datetime(iqr_filtered_df_sorted[\"image_timestamp\"])\n",
        "timestamps_to_keep = iqr_filtered_df_sorted[\"image_timestamp\"].unique()\n",
        "filtered_discharge_df = usgs_discharge_df[usgs_discharge_df[\"datetime\"].isin(timestamps_to_keep)]\n",
        "\n",
        "# Merge stage and discharge for fitting\n",
        "discharge_df = pd.merge(\n",
        "    iqr_filtered_df_sorted,\n",
        "    filtered_discharge_df[[\"datetime\", \"discharge\"]],\n",
        "    left_on=\"image_timestamp\",\n",
        "    right_on=\"datetime\",\n",
        "    how=\"inner\"\n",
        ").dropna(subset=[\"stage\", \"discharge\"])\n",
        "\n",
        "# Extract stage and discharge for curve fitting\n",
        "h = discharge_df[\"stage\"].values\n",
        "Q = discharge_df[\"discharge\"].values\n",
        "\n",
        "# Define rating function and fit\n",
        "def rating_curve(h, a, b, h0):\n",
        "    return a * (h - h0) ** b\n",
        "\n",
        "initial_guess = (1.0, 2.0, 1.5)\n",
        "popt, _ = curve_fit(rating_curve, h, Q, p0=initial_guess)\n",
        "a, b, h0 = popt\n",
        "\n",
        "popt"
      ],
      "metadata": {
        "id": "CQrhwERgBO51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usgs_discharge_df.head()"
      ],
      "metadata": {
        "id": "6fSY-Fgt7mxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitted rating curve parameters\n",
        "a = 0.103\n",
        "b = 1.177\n",
        "h0 = 61.138\n",
        "\n",
        "# Define discharge prediction function\n",
        "def predict_discharge(h):\n",
        "    h = np.array(h)\n",
        "    return a * np.power(np.maximum(h - h0, 0), b)\n",
        "\n",
        "# Apply to your in-memory DataFrame\n",
        "predicted_stage_df[\"predicted_discharge_cms\"] = predict_discharge(predicted_stage_df[\"predicted_stage\"])\n",
        "predicted_stage_df"
      ],
      "metadata": {
        "id": "Wm0MFweaBkxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_stage_df.to_csv(\"predicted_stage_discharge.csv\", index=False)"
      ],
      "metadata": {
        "id": "Gm74aFlQDeM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert timestamp to datetime for both datasets\n",
        "#predicted_stage_df[\"timestamp\"] = pd.to_datetime(predicted_stage_df[\"timestamp\"])\n",
        "#filtered_discharge_df[\"datetime\"] = pd.to_datetime(filtered_discharge_df[\"datetime\"])\n",
        "\n",
        "# Merge predicted discharge with observed discharge based on timestamp\n",
        "comparison_df = pd.merge(\n",
        "    predicted_stage_df,\n",
        "    filtered_discharge_df[[\"datetime\", \"discharge\"]],\n",
        "    left_on=\"timestamp\",\n",
        "    right_on=\"datetime\",\n",
        "    how=\"inner\"\n",
        ").dropna(subset=[\"predicted_discharge_cms\", \"discharge\"])\n",
        "\n",
        "# Calculate performance metrics\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "r2 = r2_score(comparison_df[\"discharge\"], comparison_df[\"predicted_discharge_cms\"])\n",
        "mae = mean_absolute_error(comparison_df[\"discharge\"], comparison_df[\"predicted_discharge_cms\"])\n",
        "mse = mean_squared_error(comparison_df[\"discharge\"], comparison_df[\"predicted_discharge_cms\"])\n",
        "\n",
        "metrics = {\n",
        "    \"R²\": r2,\n",
        "    \"MAE\": mae,\n",
        "    \"MSE\": mse\n",
        "}\n",
        "\n",
        "metrics"
      ],
      "metadata": {
        "id": "Zwi73UHHB6DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "h_fit = np.linspace(h.min(), h.max(), 200)\n",
        "Q_fit = rating_curve(h_fit, *popt)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(h, Q, label=\"Observed Discharge\", color=\"black\", alpha=0.6)\n",
        "plt.plot(h_fit, Q_fit, label=\"Fitted Rating Curve\", color=\"red\", linewidth=2)\n",
        "plt.xlabel(\"Stage (cm)\")\n",
        "plt.ylabel(\"Discharge (cms)\")\n",
        "plt.title(\"Stage-Discharge Rating Curve\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"rating_curve.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xhi58G52J0In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge predicted discharge with observed discharge\n",
        "discharge_comparison_df = pd.merge(\n",
        "    predicted_stage_df[[\"timestamp\", \"predicted_discharge_cms\"]],\n",
        "    filtered_discharge_df[[\"datetime\", \"discharge\"]],\n",
        "    left_on=\"timestamp\",\n",
        "    right_on=\"datetime\",\n",
        "    how=\"inner\"\n",
        ").dropna()\n",
        "\n",
        "# Sort by time for clean plotting\n",
        "discharge_comparison_df = discharge_comparison_df.sort_values(\"timestamp\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"discharge\"], label=\"USGS Observed Discharge\", linewidth=2)\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"predicted_discharge_cms\"], label=\"Predicted Discharge\", linestyle=\"--\", linewidth=2)\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Discharge (cms)\")\n",
        "plt.title(\"Predicted vs Observed Discharge\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mF9YhhQeCG-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import savgol_filter\n",
        "\n",
        "# Apply Savitzky–Golay filter (window must be odd and >= polyorder + 2)\n",
        "discharge_comparison_df[\"predicted_discharge_smoothed\"] = savgol_filter(\n",
        "    discharge_comparison_df[\"predicted_discharge_cms\"], window_length=11, polyorder=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "d5pGwEMgLhLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply 5-point moving average (adjust window size as needed)\n",
        "discharge_comparison_df[\"predicted_discharge_smoothed\"] = (\n",
        "    discharge_comparison_df[\"predicted_discharge_cfs\"].rolling(window=5, center=True).mean()\n",
        ")\n"
      ],
      "metadata": {
        "id": "igFygH9qLmDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot observed and predicted discharge\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"discharge\"],\n",
        "         label=\"USGS Observed\", linewidth=2)\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"predicted_discharge_smoothed\"],\n",
        "         label=\"Predicted\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "# Set labels and title with larger fonts\n",
        "plt.xlabel(\"Timestamp\", fontsize=14)\n",
        "plt.ylabel(\"Discharge (cms)\", fontsize=14)\n",
        "plt.title(\"Predicted vs Observed Discharge\", fontsize=14)\n",
        "\n",
        "# Tick font sizes\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "\n",
        "# Legend and grid\n",
        "plt.legend(fontsize=14)\n",
        "plt.grid(True)\n",
        "\n",
        "# Layout\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"discharge_timeseries.png\", dpi=300, bbox_inches='tight')  # Optional save\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V9BSbM6yLwPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare values\n",
        "x = comparison_df[\"discharge\"].values.reshape(-1, 1)  # Observed\n",
        "y = comparison_df[\"predicted_discharge_cms\"].values  # Predicted\n",
        "\n",
        "# Fit regression line\n",
        "reg_model = LinearRegression()\n",
        "reg_model.fit(x, y)\n",
        "slope = reg_model.coef_[0]\n",
        "intercept = reg_model.intercept_\n",
        "y_pred_line = reg_model.predict(x)\n",
        "\n",
        "# Regression equation string\n",
        "reg_eq = f\"y = {slope:.3f}x + {intercept:.3f}\"\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(7, 7))\n",
        "sns.scatterplot(x=comparison_df[\"discharge\"], y=comparison_df[\"predicted_discharge_cms\"],\n",
        "                alpha=0.6, edgecolor='k', s=50, label=\"Predictions\")\n",
        "plt.plot([x.min(), x.max()], [x.min(), x.max()], 'r--', label=\"1:1 Line\", linewidth=2)\n",
        "plt.plot(x, y_pred_line, color=\"darkgreen\", linestyle='-', linewidth=2, label=f\"Regression Line\\n({reg_eq})\")\n",
        "\n",
        "plt.xlabel(\"Observed Discharge (cms)\", fontsize=14)\n",
        "plt.ylabel(\"Predicted Discharge (cms)\", fontsize=14)\n",
        "plt.title(\"Observed vs Predicted Discharge with Regression Line\", fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"discharge_scatter.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aImoXyuEGcdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute residuals\n",
        "comparison_df[\"residual\"] = comparison_df[\"discharge\"] - comparison_df[\"predicted_discharge_cfs\"]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(comparison_df[\"timestamp\"], comparison_df[\"residual\"], color=\"darkred\", label=\"Discharge Residual\")\n",
        "plt.axhline(0, color='black', linestyle='--')\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Residual (cfs)\")\n",
        "plt.title(\"Discharge Prediction Error Over Time\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "#plt.savefig(\"discharge_residuals_over_time.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LUBfd5kAG9v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.kdeplot(comparison_df[\"residual\"], fill=True, color=\"steelblue\", alpha=0.6)\n",
        "plt.axvline(0, color='black', linestyle='--')\n",
        "plt.xlabel(\"Prediction Error (cfs)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Distribution of Discharge Prediction Error\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "#plt.savefig(\"discharge_error_distribution.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z0FKSAPuG4Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EDQANSnBPhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import curve_fit\n",
        "\n",
        "#predicted_stage = pd.read_csv(\"/content/predicted_stage_discharge.csv\", skiprows=1, header=None)\n",
        "usgs_discharge_df = pd.read_csv(\"/content/USGS_Discharge_FD.csv\", skiprows=1, header=None)\n",
        "\n",
        "# Rename the needed columns based on previous structure\n",
        "usgs_discharge_df = usgs_discharge_df.rename(columns={2: \"datetime\", 4: \"discharge\"})\n",
        "usgs_discharge_df[\"datetime\"] = pd.to_datetime(usgs_discharge_df[\"datetime\"], errors=\"coerce\")\n",
        "usgs_discharge_df[\"discharge\"] = pd.to_numeric(usgs_discharge_df[\"discharge\"], errors=\"coerce\")\n",
        "usgs_discharge_df = usgs_discharge_df.dropna(subset=[\"datetime\", \"discharge\"])\n",
        "\n",
        "# Filter discharge data to only timestamps that exist in iqr_filtered_df_sorted\n",
        "iqr_filtered_df_sorted[\"image_timestamp\"] = pd.to_datetime(iqr_filtered_df_sorted[\"image_timestamp\"])\n",
        "timestamps_to_keep = iqr_filtered_df_sorted[\"image_timestamp\"].unique()\n",
        "filtered_discharge_df = usgs_discharge_df[usgs_discharge_df[\"datetime\"].isin(timestamps_to_keep)]\n",
        "\n",
        "# Merge stage and discharge for fitting\n",
        "discharge_df = pd.merge(\n",
        "    iqr_filtered_df_sorted,\n",
        "    filtered_discharge_df[[\"datetime\", \"discharge\"]],\n",
        "    left_on=\"image_timestamp\",\n",
        "    right_on=\"datetime\",\n",
        "    how=\"inner\"\n",
        ").dropna(subset=[\"stage\", \"discharge\"])\n",
        "\n",
        "# Extract stage and discharge for curve fitting\n",
        "h = discharge_df[\"stage\"].values\n",
        "Q = discharge_df[\"discharge\"].values\n",
        "\n",
        "# Define rating function and fit\n",
        "def rating_curve(h, a, b, h0):\n",
        "    return a * (h - h0) ** b\n",
        "\n",
        "initial_guess = (1.0, 2.0, 1.5)\n",
        "popt, _ = curve_fit(rating_curve, h, Q, p0=initial_guess)\n",
        "a, b, h0 = popt\n",
        "\n",
        "popt"
      ],
      "metadata": {
        "id": "G9RznEQOsIYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitted rating curve parameters\n",
        "a = 187.05\n",
        "b = 1.313\n",
        "h0 = 1.933\n",
        "\n",
        "# Define discharge prediction function\n",
        "def predict_discharge(h):\n",
        "    h = np.array(h)\n",
        "    return a * np.power(np.maximum(h - h0, 0), b)\n",
        "\n",
        "# Apply to your in-memory DataFrame\n",
        "predicted_stage_df[\"predicted_discharge_cfs\"] = predict_discharge(predicted_stage_df[\"predicted_stage\"])\n",
        "predicted_stage_df"
      ],
      "metadata": {
        "id": "wZSlBoJWtt3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_stage_df.to_csv(\"predicted_stage_discharge.csv\", index=False)"
      ],
      "metadata": {
        "id": "MJ_mgc7qZxOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert timestamp to datetime for both datasets\n",
        "#predicted_stage_df[\"timestamp\"] = pd.to_datetime(predicted_stage_df[\"timestamp\"])\n",
        "#filtered_discharge_df[\"datetime\"] = pd.to_datetime(filtered_discharge_df[\"datetime\"])\n",
        "\n",
        "# Merge predicted discharge with observed discharge based on timestamp\n",
        "comparison_df = pd.merge(\n",
        "    predicted_stage_df,\n",
        "    filtered_discharge_df[[\"datetime\", \"discharge\"]],\n",
        "    left_on=\"timestamp\",\n",
        "    right_on=\"datetime\",\n",
        "    how=\"inner\"\n",
        ").dropna(subset=[\"predicted_discharge_cfs\", \"discharge\"])\n",
        "\n",
        "# Calculate performance metrics\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "r2 = r2_score(comparison_df[\"discharge\"], comparison_df[\"predicted_discharge_cfs\"])\n",
        "mae = mean_absolute_error(comparison_df[\"discharge\"], comparison_df[\"predicted_discharge_cfs\"])\n",
        "mse = mean_squared_error(comparison_df[\"discharge\"], comparison_df[\"predicted_discharge_cfs\"])\n",
        "\n",
        "metrics = {\n",
        "    \"R²\": r2,\n",
        "    \"MAE\": mae,\n",
        "    \"MSE\": mse\n",
        "}\n",
        "\n",
        "metrics\n"
      ],
      "metadata": {
        "id": "bNuXTPicuPbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_discharge_df"
      ],
      "metadata": {
        "id": "wBNOlbSMPU-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge predicted discharge with observed discharge\n",
        "discharge_comparison_df = pd.merge(\n",
        "    predicted_stage_df[[\"timestamp\", \"predicted_discharge_cfs\"]],\n",
        "    filtered_discharge_df[[\"datetime\", \"discharge\"]],\n",
        "    left_on=\"timestamp\",\n",
        "    right_on=\"datetime\",\n",
        "    how=\"inner\"\n",
        ").dropna()\n",
        "\n",
        "# Sort by time for clean plotting\n",
        "discharge_comparison_df = discharge_comparison_df.sort_values(\"timestamp\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"discharge\"], label=\"USGS Observed Discharge\", linewidth=2)\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"predicted_discharge_cfs\"], label=\"Predicted Discharge\", linestyle=\"--\", linewidth=2)\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Discharge (cfs)\")\n",
        "plt.title(\"Predicted vs Observed Discharge\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MrJuBBwVPfbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discharge_comparison_df.to_csv(\"output_filename.csv\", index=False)"
      ],
      "metadata": {
        "id": "XbtNH5c7REDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import savgol_filter\n",
        "\n",
        "# Apply Savitzky–Golay filter (window must be odd and >= polyorder + 2)\n",
        "discharge_comparison_df[\"predicted_discharge_smoothed\"] = savgol_filter(\n",
        "    discharge_comparison_df[\"predicted_discharge_cfs\"], window_length=11, polyorder=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "CHWuo56RarOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply 5-point moving average (adjust window size as needed)\n",
        "discharge_comparison_df[\"predicted_discharge_smoothed\"] = (\n",
        "    discharge_comparison_df[\"predicted_discharge_cfs\"].rolling(window=5, center=True).mean()\n",
        ")\n"
      ],
      "metadata": {
        "id": "7DH2P0Jdawzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"discharge\"], label=\"USGS Observed\", linewidth=2)\n",
        "plt.plot(discharge_comparison_df[\"timestamp\"], discharge_comparison_df[\"predicted_discharge_smoothed\"], label=\"Predicted\", linestyle=\"--\", linewidth=2)\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.ylabel(\"Discharge (cfs)\")\n",
        "plt.title(\"Predicted vs Observed Discharge\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p45w-WWZayrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOZahvm6yEOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}